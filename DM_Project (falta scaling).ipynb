{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda60275",
   "metadata": {},
   "source": [
    "# Group 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49650af4",
   "metadata": {},
   "source": [
    "- Ana Margarida Valente, 20240936\n",
    "- Catarina Carneiro, 20240690\n",
    "- Rui Reis, 20240854\n",
    "- Mara Mesquita, 20241039"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc8b67",
   "metadata": {},
   "source": [
    "Add indice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98cf104",
   "metadata": {},
   "source": [
    "Add descriprion of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed1d56-a6b5-4735-b4d1-d4f2c7be6938",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35ae1e-4aba-4fa5-af80-418039ded684",
   "metadata": {},
   "source": [
    "## 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19581a5b-1db6-4699-bbbc-f6c75127ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "\n",
    "from itertools import product\n",
    "from scipy.stats import skewnorm\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "# for better resolution plots\n",
    "%config InlineBackend.figure_format = 'retina' # optionally, you can change 'svg' to 'retina'\n",
    "\n",
    "# Setting seaborn style\n",
    "sns.set()\n",
    "\n",
    "# Display all the df\n",
    "pd.options.display.max_columns = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94ac65-a520-4c82-9e2a-df1131c8af6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.2 Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb90324-20f2-4e21-839c-ab32ad4be487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv(r\"C:\\Users\\anama\\OneDrive\\Ambiente de Trabalho\\Mestrado\\Projects\\DM2425_ABCDEats_DATASET.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183f11c-08f6-45a2-aa04-084720cd64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a backup of the df\n",
    "df_backup=df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bfb239",
   "metadata": {},
   "source": [
    "## Variables:\n",
    "- customer_id: Unique identifier for each customer.\n",
    "- customer_region: Geographic region where the customer is located.\n",
    "- customer_age: Age of the customer.\n",
    "- vendor_count: Number of unique vendors the customer has ordered from.\n",
    "- product_count: Total number of products the customer has ordered.\n",
    "- is_chain: Indicates whether the customerâ€™s order was from a chain restaurant.\n",
    "- first_order: Number of days from the start of the dataset when the customer first placed an order.\n",
    "- last_order: Number of days from the start of the dataset when the customer most recently placed an order.\n",
    "- last_promo: The category of the promotion or discount most recently used by the customer.\n",
    "- payment_method: Method most recently used by the customer to pay for their orders.\n",
    "- CUI_American,CUI_Asian,CUI_Chinese,CUI_Italian, etc.: The amount in monetary units spent by the customer from the indicated type of cuisine.\n",
    "- DOW_0 to DOW_6: Number of orders placed on each day of the week (0 = Sunday, 6 = Saturday).\n",
    "- HR_0 to HR_23: Number of orders placed during each hour of the day (0 = midnight, 23 = 11 PM).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d85ae8-6097-48d7-bb39-a11f9a3a0428",
   "metadata": {},
   "source": [
    "# 2. Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d4688-a740-43e4-a5b2-19a4a49503f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33699a-2bee-40ca-8e92-67158c196a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de0739-f18c-46d1-8a5a-880984a9ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check columns\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89829569-7397-4910-aaf0-b4c7b60e81aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Minor changes to the Data\n",
    "1) Change the DOW columns to the days of the week names\n",
    "\n",
    "2) Create new variables\n",
    "  - Time Periods\n",
    "  - Age Group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec47ed-9a12-4168-b45e-96c6b7aa445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)\n",
    "df= df.rename(columns={'DOW_0':'Sunday', 'DOW_1':'Monday', 'DOW_2':'Tuesday', 'DOW_3':'Wednesday', 'DOW_4':'Thursday', 'DOW_5':'Friday','DOW_6':'Saturday'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f64d27a-c261-4312-aa3e-51bb64af43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "df['early_morning(0h-5h)'] = df.filter(regex=r'^HR_[0-5]$').sum(axis=1).astype(int)\n",
    "\n",
    "df['morning(6h-11h)'] = df.filter(regex=r'^HR_([6-9]|1[0-1])$').sum(axis=1).astype(int)\n",
    "\n",
    "df['afternoon(12h-17h)']= df.filter(regex=r'^HR_1[2-7]$').sum(axis=1).astype(int)\n",
    "\n",
    "df['night(18h-23h)'] = df.filter(regex=r'^HR_(1[8-9]|2[0-3])$').sum(axis=1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3dfd77-756e-4299-936a-604b5ad4e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "age_labels = ['Teenagers (15-19)', 'Young Adults (20-29)', 'Adults (30-49)', 'Middle-aged (50-64)', 'Seniors (65-80)']\n",
    "df['age_group'] = pd.cut(df['customer_age'], bins=[15, 20, 30, 50, 65, 80], labels=age_labels, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a3b244-9d1c-494b-82a4-16a03c030567",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1dbb6b-89c0-4df2-bf8b-aefe6d15de5e",
   "metadata": {},
   "source": [
    "### Data types:\n",
    "- customer_age -> float? (change to int)\n",
    "- first_order -> float? (change to int or date time (days) ?)\n",
    "- last_order (change to date time (days) ?)\n",
    "- HR_0 -> float? (change to int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495850c6-85c8-4449-ac03-b51c9d66f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a df only with the original variables (Drop the new columns created)\n",
    "df_original = df.drop(columns=['early_morning(0h-5h)','morning(6h-11h)','afternoon(12h-17h)','night(18h-23h)','age_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd667898-f938-4af8-8307-5eb78e486783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "df_original.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5b9121",
   "metadata": {},
   "source": [
    "### \n",
    "Fix data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19496a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_age'] = df['customer_age'].astype('Int64')\n",
    "df['first_order'] = df['first_order'].astype('Int64')\n",
    "df['HR_0'] = df['HR_0'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36583e-fb8f-4551-a121-f9bc2a830e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check only the original df = Categorical Variables\n",
    "df_original.describe(include=\"O\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c9137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check only the original df = Numerical Variables\n",
    "df_original.describe(include=np.number).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c41f432-03e7-4d93-bf58-ba592812371d",
   "metadata": {},
   "source": [
    "## Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf817e91-a70e-4e45-b995-36d17c524ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60193bce-ac5c-4f1b-b30c-4482a116fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c6199-39d9-4f74-857e-caef5ae474ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the % of the missing values:\n",
    "missing_percentage = (df.isnull().mean() * 100).sort_values(ascending=False)\n",
    "\n",
    "print(\"Percentage of Missing Values:\")\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4585705-f834-4ed4-8b32-0eb84c445cf6",
   "metadata": {},
   "source": [
    "\n",
    "Missing Values : HR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db8ff52-e0f4-4e67-bd48-93da40f7d32f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Check when HR_0 = NaN, which is the variable with most missing values\n",
    "nan_HR_0 = df[df['HR_0'].isna()]\n",
    "pd.set_option('display.max_columns', None)\n",
    "nan_HR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab08967-8343-4684-892e-0f60970e0ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the columns of the DOW and the HR columns\n",
    "dow_columns = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "hr_columns = [col for col in df.columns if col.startswith('HR_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e593dac0-3f57-4329-865b-aecc2516091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To replace the NaN's of HR_0, let's compare the sum of orders of the DOW with the sum of orders of the HR:\n",
    "#If it's the same, then HR_0 should be 0, if not, it's the difference between the 2 values, since the sum should be equal\n",
    "\n",
    "row_sum_dow = df[dow_columns].sum(axis=1)\n",
    "row_sum_hr = df[hr_columns].sum(axis=1)\n",
    "\n",
    "row_difference = row_sum_dow - row_sum_hr\n",
    "\n",
    "df.loc[df['HR_0'].isna(), 'HR_0'] = row_difference\n",
    "\n",
    "df['HR_0'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b36f5-b24d-4116-b129-d258efd64cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HR_0'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the sum of the DOW is equal to the sum of the Hours; It must be\n",
    "check = (df[dow_columns].sum(axis=1) == df[hr_columns].sum(axis=1)).all()\n",
    "\n",
    "if check:\n",
    "    print(\"Yes\")\n",
    "else:\n",
    "    print(\"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f3d3c-867c-44ba-90e5-299379ba3461",
   "metadata": {},
   "source": [
    "\n",
    "Missing Values : first_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ef338-37a2-440a-a1a1-717e8f069095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check when first_order = NaN\n",
    "nan_first_order = df[df['first_order'].isna()]\n",
    "nan_first_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f1e56-2590-43ba-8085-ab94f82adcd0",
   "metadata": {},
   "source": [
    "It seem that when the first_order is a missing value, the last_order = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e00dbb-654b-4002-8e25-058c1518789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['first_order'].isna() & (df_original['last_order'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we are checking to see if in this situation, there was only one order placed\n",
    "check = (df[df['first_order'].isna() & (df['last_order'] == 0)][dow_columns].sum(axis=1) == 1).all()\n",
    "\n",
    "if check:\n",
    "    print(\"All rows have row_sum_dow equal to 1 (indicating only one order).\")\n",
    "else:\n",
    "    print(\"There are rows where row_sum_dow is not 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaced8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check which rows do not meet the condition\n",
    "non_matching_rows = df[(df['first_order'].isna() & (df['last_order'] == 0)) & (df[dow_columns].sum(axis=1) != 1)]\n",
    "\n",
    "non_matching_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848c6968",
   "metadata": {},
   "source": [
    "There are only 2 cases that do not meet the condition. Both cases show that 2 orders were placed on the same day (Saturday). \n",
    "\n",
    "Based on this previous analysis, we will assume that when first_order is missing it should be replaced with 0, ensuring that both first_order and last_order occur on the same day (the day the dataset begins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e3a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_order is missing only when last_order = 0\n",
    "#first_order cannot happen after last_order. So we will set the missing first_order values to 0\n",
    "df.loc[df['first_order'].isna() & (df['last_order'] == 0), 'first_order'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ddae8-4aad-4d9f-8d0c-66eaba88d239",
   "metadata": {},
   "source": [
    "\n",
    "Missing Values : customer_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b511d-eb79-4798-95c4-1f25453d4794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check when customer_age = NaN\n",
    "nan_customer_age = df[df['customer_age'].isna()]\n",
    "nan_customer_age\n",
    "\n",
    "#Maybe replace the missing values with the mean or median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['customer_age'].dropna(), bins=30, edgecolor='black')  \n",
    "plt.title('Histogram of Age')\n",
    "plt.xlabel('Age') \n",
    "plt.ylabel('Frequency') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c94605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the histogram is skewed, the median is preferred to replace the missing values\n",
    "median_age = df['customer_age'].median()\n",
    "df['customer_age'] = df['customer_age'].fillna(median_age)\n",
    "print(f\"Median = {median_age}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e50ac26",
   "metadata": {},
   "source": [
    "Now, to handle the missing values in the age_group column caused by missing customer_age, we need to replace them with the category \"Young Adults (20-29)\", since the median (26) falls into this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_group'] = df['age_group'].fillna(\"Young Adults (20-29)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c785c",
   "metadata": {},
   "source": [
    "## Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c492246-bc08-4981-bb03-47c3e0803f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791fbad-b123-44cb-aefd-e966a1f957df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df_original.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d562c7-2d1d-4241-a0b1-ee7fdbef2035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#% of duplicates:\n",
    "df.duplicated().mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify customer_id duplicated (since it should be a unique value, representing 1 customer)\n",
    "duplicate_values = df['customer_id'].value_counts()[df['customer_id'].value_counts() > 1]\n",
    "\n",
    "duplicate_rows = df[df['customer_id'].isin(duplicate_values.index)]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f'Total: {len(duplicate_rows)}') #drop it?\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fed18",
   "metadata": {},
   "source": [
    "The duplicates are only the cases where the customer_id is duplicated, meaning that are 2 entries of the same customer in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c9821f-54d3-4707-9989-679c95449dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the duplicates, since it's a very small amount????\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7811ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Customer_id\n",
    "df = df.drop('customer_id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c78b29-5ba9-4fc0-857f-3635cc00bf25",
   "metadata": {},
   "source": [
    "## Check for unique and strange values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88820e11",
   "metadata": {},
   "source": [
    "Vendor_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vendor_count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['vendor_count'] == 41]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd087397",
   "metadata": {},
   "source": [
    "Product_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8790f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['product_count'] == 269]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eae9ce",
   "metadata": {},
   "source": [
    "Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542cd87-ea8c-4d57-bca8-a1accb82c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df[df['customer_region'] == '-']) / len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a4800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '-' with the mode\n",
    "mode_value = df['customer_region'].mode()[0]  \n",
    "\n",
    "df['customer_region'] = df['customer_region'].replace('-', mode_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4b8c2a",
   "metadata": {},
   "source": [
    "- '-' -> Strange = 1,386%; Maybe use mode or drop?\n",
    "- There are 3 cities, so should we aggregate the cities by the first number of the region? (2,4,8)\n",
    "- Another possibilitie is to aggregate the cities based on the frequency of customers. (1 (>5000) - 8670, 4660, 2360; 2 (<5000 & >1000) - 2440, 4140; 3 (<1000) - 8370, 2490, -, 8550 )\n",
    "- (issue to think about and address in the future, 1 option keeps the distribution balanced and the other does not)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e87d0",
   "metadata": {},
   "source": [
    " Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e767ba01-520d-4f41-b8df-2e94dcaaf669",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87afe5ed-b7ed-4755-b9ed-49683975ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['customer_age'] == 15) | (df['customer_age'] == 16)| (df['customer_age'] == 17)]\n",
    "#It could be a problem since it's a minor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8d667",
   "metadata": {},
   "source": [
    "Promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244012c0-7cd8-48c2-b7f6-de19a69e9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_promo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e51d0",
   "metadata": {},
   "source": [
    "- '-' -> Changing to 'NO PROMO', to be more perceptible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222df8aa-9e01-41b5-9deb-08639823df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_promo'] = df['last_promo'].replace('-', 'N0 PROMO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7424998b",
   "metadata": {},
   "source": [
    "Payment Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b372ca-bf87-42c2-8024-3eded93e5a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['payment_method'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa322e2a",
   "metadata": {},
   "source": [
    "First Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29df8769-a71e-41a9-888a-d2843b932132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_order'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab5518-753d-4f85-8b10-6bc4ea89828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_order'].max()\n",
    "#Makes sense because the dataset is from a three-month period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f0c859",
   "metadata": {},
   "source": [
    "Last Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28e930-8606-4f1a-a8af-b6802b821d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_order'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e131a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_order'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780e7758",
   "metadata": {},
   "source": [
    "Is Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b0432",
   "metadata": {},
   "source": [
    "- This variable needs to be fixed. The metadata does not correspond to the dataset\n",
    "\n",
    "- Make it binary (correspondant to the metadata); Change the info on the metadata to be coherent to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_chain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f9a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the orders are on bevarages\n",
    "df[df['is_chain'] == 83]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1ad7b2",
   "metadata": {},
   "source": [
    "Change is_chain to Binary Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca8a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "df['is_chain'] = (df['is_chain'] > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a737b",
   "metadata": {},
   "source": [
    "DOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d949d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in dow_columns:\n",
    "    unique_values = df[column].unique()  # Get unique values\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"Unique Values: {unique_values}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42701cf8",
   "metadata": {},
   "source": [
    "Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3add42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in hr_columns:\n",
    "    unique_values = df[column].unique()  # Get unique values\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"Unique Values: {unique_values}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['HR_8'] == 52]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c50c69",
   "metadata": {},
   "source": [
    "Cuisine Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385949da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col.startswith('CUI_'):\n",
    "        unique_values = df[col].unique()  \n",
    "        print(f\"Column: {col}\")\n",
    "        print(f\"Unique Values: {unique_values}\")\n",
    "        print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e80dfe3-c788-440e-bb98-9aaf7eae3be0",
   "metadata": {},
   "source": [
    "# 3. Feature Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af645a",
   "metadata": {},
   "source": [
    "Define groups of columns and create a new feature = Sum_of_Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbf8af-1724-4c2a-9905-49b622197d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define groups of columns of the same category\n",
    "dow_columns = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "hr_columns = [col for col in df.columns if col.startswith('HR_')]\n",
    "CUI_columns = [col for col in df.columns if col.startswith('CUI_')]\n",
    "time_columns = ['early_morning(0h-5h)','morning(6h-11h)','afternoon(12h-17h)', 'night(18h-23h)']\n",
    "\n",
    "#Define the sum of the columns\n",
    "DOW_counts = df[dow_columns].sum()\n",
    "HR_counts = df[hr_columns].sum()\n",
    "CUI_counts = df[CUI_columns].sum()\n",
    "time_counts = df[time_columns].sum()\n",
    "\n",
    "#Define a new Feature that contains the sum of orders by customer (it has the same info as DOW_counts and HR_counts)\n",
    "df['Sum_of_Orders'] = df[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b19552e",
   "metadata": {},
   "source": [
    "Check comparation between First Order and Last Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac77c95-80fb-4cb8-8783-43ab3996bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df[df['last_order'] < df['first_order']]\n",
    "print(result)\n",
    "#All good, since it wouldn't make sense if there was a last order before a first order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad330f",
   "metadata": {},
   "source": [
    " Define Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54a355-0d5a-4755-810c-2ee2b82bb32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features=['customer_age', 'vendor_count','product_count', 'first_order', 'last_order']\n",
    "categorical_features=['customer_region','last_promo','payment_method','age_group', 'is_chain']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e84254",
   "metadata": {},
   "source": [
    "## Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae74d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_outliers(data):\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_lim = Q1 - 1.5 * IQR\n",
    "    upper_lim = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data < lower_lim) | (data > upper_lim)]\n",
    "    percentage = (len(outliers) / len(data)) * 100  \n",
    "    return len(outliers), percentage, lower_lim, upper_lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcff13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_features:\n",
    "    print(f\" Statistics for column: {col}\")\n",
    "    \n",
    "    # Calculate key statistics\n",
    "    mean = df[col].mean()\n",
    "    median = df[col].median()\n",
    "    std_dev = df[col].std()\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    skewness = df[col].skew()\n",
    "    kurtosis = df[col].kurt()\n",
    "\n",
    "    # Display the statistics\n",
    "    print(f'  Mean: {mean:.2f}')\n",
    "    print(f'  Median: {median:.2f}')\n",
    "    print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "    print(f'  Min: {min_val}')\n",
    "    print(f'  Max: {max_val}')\n",
    "    print(f'  Skewness: {skewness:.2f}')\n",
    "    print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "    print('-' * 50 )\n",
    "    \n",
    "    # Visualization of each Variable:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Histogram of {col}')\n",
    "\n",
    "    # Boxplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "\n",
    "    # Analyze outliers for the numerical variables\n",
    "    outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "    print(f'Count of outliers: {outlier_count}')\n",
    "    print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "    print(f'Lower Lim:{lower_lim}')\n",
    "    print(f'Upper Lim:{upper_lim}')\n",
    "    print('-' * 40)\n",
    "   \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47dd7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_dow_cui=['CUI_American', 'CUI_Asian', 'CUI_Beverages','CUI_Cafe', 'CUI_Chicken Dishes', \n",
    "            'CUI_Chinese', 'CUI_Desserts','CUI_Healthy', 'CUI_Indian', 'CUI_Italian', \n",
    "            'CUI_Japanese','CUI_Noodle Dishes', 'CUI_OTHER', 'CUI_Street Food / Snacks','CUI_Thai', \n",
    "            'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday','Friday', 'Saturday', \n",
    "            'HR_0', 'HR_1', 'HR_2', 'HR_3', 'HR_4', 'HR_5','HR_6', 'HR_7', 'HR_8', 'HR_9', 'HR_10', \n",
    "            'HR_11', 'HR_12', 'HR_13','HR_14', 'HR_15', 'HR_16', 'HR_17', 'HR_18', 'HR_19', 'HR_20', 'HR_21','HR_22', 'HR_23']\n",
    "\n",
    "for col in hr_dow_cui:\n",
    "    print(f\" Statistics for column: {col}\")\n",
    "    \n",
    "    # Calculate key statistics\n",
    "    mean = df[col].mean()\n",
    "    median = df[col].median()\n",
    "    std_dev = df[col].std()\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    skewness = df[col].skew()\n",
    "    kurtosis = df[col].kurt()\n",
    "\n",
    "    # Display the statistics\n",
    "    print(f'  Mean: {mean:.2f}')\n",
    "    print(f'  Median: {median:.2f}')\n",
    "    print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "    print(f'  Min: {min_val}')\n",
    "    print(f'  Max: {max_val}')\n",
    "    print(f'  Skewness: {skewness:.2f}')\n",
    "    print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "    print('-' * 50 )\n",
    "    \n",
    "    # Visualization of each Variable:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Histogram of {col}')\n",
    "\n",
    "    # Boxplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "\n",
    "    # Analyze outliers for the numerical variables\n",
    "    outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "    print(f'Count of outliers: {outlier_count}')\n",
    "    print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "    print(f'Lower Lim:{lower_lim}')\n",
    "    print(f'Upper Lim:{upper_lim}')\n",
    "    print('-' * 40)\n",
    "   \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f4756-e113-4d81-a7b8-7e41e3a89c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "DOW_counts.plot(kind='bar', \n",
    "                color='lightsteelblue', \n",
    "                edgecolor='black')\n",
    "\n",
    "plt.title('Number of Orders for Each Day of the Week')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca2e902-69dd-408e-af64-ee4ddc2e813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "HR_counts.plot(kind='bar', \n",
    "               color='lightsteelblue', \n",
    "               edgecolor='black')\n",
    "\n",
    "plt.title('Number of Orders for Each Hour')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f41ed-9ccb-4df0-beb6-1b694c86781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "time_counts.plot(kind='bar', \n",
    "                 color='lightsteelblue', \n",
    "                 edgecolor='black')\n",
    "\n",
    "plt.title('Number of Orders for Time Period')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Number of Ordes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa10e23-77bd-414f-b891-08e8e478ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUI_counts_sorted = CUI_counts.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "CUI_counts_sorted.plot(kind='bar', \n",
    "                       color='lightsteelblue', \n",
    "                       edgecolor='black')\n",
    "\n",
    "plt.title('Expenses for each Type of Cuisine')\n",
    "plt.xlabel('Type of Cuisine')\n",
    "plt.ylabel('Expenses')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0197c797",
   "metadata": {},
   "source": [
    "###\n",
    " Pairwise relationships between Numerical Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8738385",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars= numerical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0224620",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df['vendor_count'], y=df['product_count'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e9c88a",
   "metadata": {},
   "source": [
    "## Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c904dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_features:\n",
    "    print(f\"Analysis for categorical column: {col}\")\n",
    "    \n",
    "    # Calculate frequency counts\n",
    "    freq_counts = df[col].value_counts()\n",
    "    \n",
    "    # Display the frequency counts\n",
    "    print(\"Frequency counts:\")\n",
    "    print(freq_counts)\n",
    "    print(\"-\"*50 )\n",
    "    \n",
    "    # Visualization for categorical variables:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(x=df[col], palette='viridis')\n",
    "    plt.title(f'Count Plot of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c4466-a909-441a-99ba-7719b7a4c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "payment_method_pie = df['payment_method'].value_counts() \\\n",
    "    .plot (kind='pie', \n",
    "           title='Payment Method', \n",
    "           autopct='%1.1f%%',\n",
    "           colors=sns.color_palette(\"viridis\"),\n",
    "           figsize=(5, 4), \n",
    "           ylabel=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b5f3e-d773-4c6a-8c47-cb24d7e1e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.05 * df['customer_region'].value_counts().sum()\n",
    "\n",
    "customer_region_counts = df['customer_region'].value_counts()\n",
    "\n",
    "others = customer_region_counts[customer_region_counts < threshold].sum()\n",
    "\n",
    "customer_region_counts = customer_region_counts[customer_region_counts >= threshold]\n",
    "customer_region_counts['Others'] = others\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "customer_region = customer_region_counts \\\n",
    "    .plot (kind='pie', \n",
    "           title='Customer Region', \n",
    "           autopct='%1.1f%%',\n",
    "           colors=sns.color_palette(\"viridis\"),\n",
    "           figsize=(5, 4), \n",
    "           ylabel=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e063bc-7879-4ed6-9549-bd7f09e1e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "#promo_df = df['last_promo'].apply(lambda x: 'NO PROMO' if(x=='-') else x  )\n",
    "promo_category = df['last_promo'].value_counts() \\\n",
    "    .plot (kind='pie', \n",
    "           title='Last Category of promotion or discount', \n",
    "           autopct='%1.1f%%',\n",
    "           colors=sns.color_palette(\"viridis\"),\n",
    "           figsize=(5, 4), \n",
    "           ylabel=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb35f73-176a-4dfe-b33b-5f0650508f8b",
   "metadata": {},
   "source": [
    "# 4. Feature Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1ef568-de11-4770-b529-a03f081e59e0",
   "metadata": {},
   "source": [
    "## New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967010c5",
   "metadata": {},
   "source": [
    "Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff17bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum number of days (most recent day in dataset)\n",
    "max_days = df['last_order'].max()\n",
    "\n",
    "# Calculate recency\n",
    "df['recency'] = max_days - df['last_order']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dbf073",
   "metadata": {},
   "source": [
    "Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07db37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate active period\n",
    "df['active_period'] = df['last_order'] - df['first_order'] + 1\n",
    "\n",
    "# Calculate frequency\n",
    "df['frequency'] = df['Sum_of_Orders'] / df['active_period']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ae3a1e",
   "metadata": {},
   "source": [
    "RFM \n",
    "- Recency = 'recency'\n",
    "- Frequency = 'frequency'\n",
    "- moentary = 'total spend'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34080cea",
   "metadata": {},
   "source": [
    "####\n",
    "We decided to create a new variable called cuisine_diversity to measure the variety of cuisines each customer orders from. This variable will help us analyze which age groups or regions tend to explore a wider range of cuisines, indicating openness to new experiences. Conversely, it will allow us to identify customers who stick to fewer options, showing a strong preference for specific types of cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0175f49-a804-4767-8312-3bb40968e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuisine diversity (number of different cuisines ordered)\n",
    "df['cuisine_diversity'] = (df[CUI_columns] > 0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad2835",
   "metadata": {},
   "outputs": [],
   "source": [
    "col='cuisine_diversity'\n",
    "# Calculate key statistics\n",
    "mean = df[col].mean()\n",
    "median = df[col].median()\n",
    "std_dev = df[col].std()\n",
    "min_val = df[col].min()\n",
    "max_val = df[col].max()\n",
    "skewness = df[col].skew()\n",
    "kurtosis = df[col].kurt()\n",
    "\n",
    "# Display the statistics\n",
    "print(f'  Mean: {mean:.2f}')\n",
    "print(f'  Median: {median:.2f}')\n",
    "print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "print(f'  Min: {min_val}')\n",
    "print(f'  Max: {max_val}')\n",
    "print(f'  Skewness: {skewness:.2f}')\n",
    "print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "print('-' * 50 )\n",
    "    \n",
    "# Visualization of each Variable\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[col], bins=10)\n",
    "plt.title(f'Histogram of {col}')\n",
    "\n",
    "# Boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df[col])\n",
    "plt.title(f'Boxplot of {col}')\n",
    "\n",
    "# Analyze outliers for the specified numerical variables\n",
    "outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "print(f'Count of outliers: {outlier_count}')\n",
    "print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "print(f'Lower Lim:{lower_lim}')\n",
    "print(f'Upper Lim:{upper_lim}')\n",
    "print('-' * 40)\n",
    "   \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956acf57",
   "metadata": {},
   "source": [
    "####\n",
    "We decided to create a new variable called total_spend to measure the overall spending of customers across different age groups and regions. This variable will help us analyze which age groups and regions have a higher capacity and willingness to spend on food orders through the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b7f9e-7ac7-48d4-a0a7-7bcacb460726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total spend per customer\n",
    "df['total_spend'] = df[CUI_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b899b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "col='total_spend'\n",
    "# Calculate key statistics\n",
    "mean = df[col].mean()\n",
    "median = df[col].median()\n",
    "std_dev = df[col].std()\n",
    "min_val = df[col].min()\n",
    "max_val = df[col].max()\n",
    "skewness = df[col].skew()\n",
    "kurtosis = df[col].kurt()\n",
    "\n",
    "# Display the statistics\n",
    "print(f'  Mean: {mean:.2f}')\n",
    "print(f'  Median: {median:.2f}')\n",
    "print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "print(f'  Min: {min_val}')\n",
    "print(f'  Max: {max_val}')\n",
    "print(f'  Skewness: {skewness:.2f}')\n",
    "print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "print('-' * 50 )\n",
    "    \n",
    "# Visualization of each Variable\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[col], bins=10, log=True)\n",
    "plt.ylabel('Log10(Count)')\n",
    "plt.title(f'Histogram of {col}')\n",
    "\n",
    "# Boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df[col])\n",
    "plt.title(f'Boxplot of {col}')\n",
    "\n",
    "# Analyze outliers for the specified numerical variables\n",
    "outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "print(f'Count of outliers: {outlier_count}')\n",
    "print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "print(f'Lower Lim:{lower_lim}')\n",
    "print(f'Upper Lim:{upper_lim}')\n",
    "print('-' * 40)\n",
    "   \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8302307f",
   "metadata": {},
   "source": [
    "\n",
    "Analyze the Sum_of_Orders Variable, creating in the beginning, that indicates the total orders by customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col='Sum_of_Orders'\n",
    "# Calculate key statistics\n",
    "mean = df[col].mean()\n",
    "median = df[col].median()\n",
    "std_dev = df[col].std()\n",
    "min_val = df[col].min()\n",
    "max_val = df[col].max()\n",
    "skewness = df[col].skew()\n",
    "kurtosis = df[col].kurt()\n",
    "\n",
    "# Display the statistics\n",
    "print(f'  Mean: {mean:.2f}')\n",
    "print(f'  Median: {median:.2f}')\n",
    "print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "print(f'  Min: {min_val}')\n",
    "print(f'  Max: {max_val}')\n",
    "print(f'  Skewness: {skewness:.2f}')\n",
    "print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "print('-' * 50 )\n",
    "    \n",
    "# Visualization of each Variable\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[col], bins=10, log=True)\n",
    "plt.ylabel('Log10(Count)')\n",
    "plt.title(f'Histogram of {col}')\n",
    "\n",
    "# Boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df[col])\n",
    "plt.title(f'Boxplot of {col}')\n",
    "\n",
    "# Analyze outliers for the specified numerical variables\n",
    "outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "print(f'Count of outliers: {outlier_count}')\n",
    "print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "print(f'Lower Lim:{lower_lim}')\n",
    "print(f'Upper Lim:{upper_lim}')\n",
    "print('-' * 40)\n",
    "   \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac28ec2c",
   "metadata": {},
   "source": [
    "City"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb09ae8",
   "metadata": {},
   "source": [
    "Aggregate Regions by the First Digit, which indicates the City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec42080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new Feature customer_city dividied into categories \n",
    "def categorize_city(customer_region):\n",
    "    if pd.isna(customer_region):  # Check if the value is NaN\n",
    "        return np.nan \n",
    "    elif customer_region== \"-\":\n",
    "        return \"Other\"\n",
    "    elif customer_region[0].isdigit():\n",
    "        return customer_region[0]\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "\n",
    "# Apply the function to create the new 'customer_city' column\n",
    "df['customer_city'] = df['customer_region'].apply(categorize_city)\n",
    "\n",
    "print(df['customer_city'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd950d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the count plot\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='customer_city', data=df)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('City', fontsize=14)\n",
    "plt.xlabel('customer_city', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28bf27",
   "metadata": {},
   "source": [
    "Create new variables: Weekdays and Weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d18f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weekdays'] = df[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']].sum(axis=1)\n",
    "df['Weekends'] = df[['Saturday', 'Sunday']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6318221",
   "metadata": {},
   "source": [
    "## Correlations and Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e450bb00-8a20-4bb3-8cc2-20f6d04dd684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df[['customer_age', \n",
    "              'vendor_count',\n",
    "               'product_count', \n",
    "              'is_chain', \n",
    "              'first_order', \n",
    "              'last_order'\n",
    "             ]].corr()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ecaca-36b5-4fa6-a236-c0ba51ab30c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_corr, \n",
    "            annot=True, \n",
    "            cmap='PiYG')\n",
    "\n",
    "plt.title('Correlation Heatmap between numerical variables', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e201b74",
   "metadata": {},
   "source": [
    "- product_count and vendor_count have a very high correlation (0,83)\n",
    "- product_count and is_chain have a very high correlation (0,83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63bab79-1e9b-4a6c-ac67-42c7964bf93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_all=df[['customer_age', 'vendor_count',\n",
    "       'product_count', 'first_order', 'last_order', 'CUI_American', 'CUI_Asian', 'CUI_Beverages',\n",
    "       'CUI_Cafe', 'CUI_Chicken Dishes', 'CUI_Chinese', 'CUI_Desserts',\n",
    "       'CUI_Healthy', 'CUI_Indian', 'CUI_Italian', 'CUI_Japanese',\n",
    "       'CUI_Noodle Dishes', 'CUI_OTHER', 'CUI_Street Food / Snacks',\n",
    "       'CUI_Thai', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday',\n",
    "       'Saturday', 'Sunday', 'HR_0', 'HR_1', 'HR_2', 'HR_3', 'HR_4', 'HR_5',\n",
    "       'HR_6', 'HR_7', 'HR_8', 'HR_9', 'HR_10', 'HR_11', 'HR_12', 'HR_13',\n",
    "       'HR_14', 'HR_15', 'HR_16', 'HR_17', 'HR_18', 'HR_19', 'HR_20', 'HR_21',\n",
    "       'HR_22', 'HR_23']].corr()\n",
    "\n",
    "plt.figure(figsize=(20, 20)) \n",
    "\n",
    "\n",
    "sns.heatmap(df_corr_all, annot=True,\n",
    "            linewidths=0.7, vmin=-1, vmax=1, square=True,\n",
    "            cbar_kws={'shrink': 0.75, 'aspect': 30}, \n",
    "            annot_kws={'size': 6 },  \n",
    "            cmap='PiYG')  \n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(rotation=0, fontsize=12)\n",
    "\n",
    "plt.title('Correlation Heatmap with all numeric variables', fontsize=16, weight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b8993-f98f-4074-8efb-57f22984f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the aggregated activity, initializing with zeros\n",
    "heatmap_data = pd.DataFrame(index=dow_columns, columns=hr_columns)\n",
    "\n",
    "# Sum of the hourly activity for each day and fill in the heatmap data\n",
    "for day in dow_columns:\n",
    "    # Summing the hourly columns for the current day and filling NaNs with zero\n",
    "    heatmap_data.loc[day] = df.loc[df[day]  > 0, hr_columns].sum().fillna(0)\n",
    "\n",
    "# Convert all data to numeric (float)\n",
    "heatmap_data = heatmap_data.astype(float)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(30, 15))\n",
    "sns.heatmap(heatmap_data, \n",
    "            cmap='PiYG', \n",
    "            linewidths=1, \n",
    "            annot=True, \n",
    "            square=True, \n",
    "            fmt='.0f')\n",
    "plt.title('Heatmap of Hourly Activity Throughout the Week')\n",
    "plt.xlabel('Hour of the Day (0-23)')\n",
    "plt.ylabel('Day of the Week')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c67d2-22fe-4132-a223-10660df92f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the aggregated activity, initializing with zeros\n",
    "heatmap_data = pd.DataFrame(index=dow_columns, columns=time_columns)\n",
    "\n",
    "# Sum the hourly activity for each day and fill in the heatmap data\n",
    "for day in dow_columns:\n",
    "    # Summing the hourly columns for the current day and filling NaNs with zero\n",
    "    heatmap_data.loc[day] = df.loc[df[day] > 0, time_columns].sum().fillna(0)\n",
    "\n",
    "# Convert all data to numeric (float)\n",
    "heatmap_data = heatmap_data.astype(float)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(heatmap_data, \n",
    "            cmap='PiYG', \n",
    "            linewidths=0.5, \n",
    "            annot=True, \n",
    "            square=True,\n",
    "            annot_kws={'size': 10 }, \n",
    "            fmt='.0f')\n",
    "plt.title('Heatmap of Period of Time Activity Throughout the Week')\n",
    "plt.xlabel('Period of Time')\n",
    "plt.ylabel('Day of the Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d819ee3-3dca-437f-96c4-05362a35bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_by_age = df.groupby('age_group')[CUI_columns].sum()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cuisine_by_age, \n",
    "            annot=True,\n",
    "            annot_kws={'size': 10 }, \n",
    "            cmap='PiYG', \n",
    "            fmt='.0f', \n",
    "            square=True)\n",
    "\n",
    "plt.title('Average Spend on each Cuisine by Age', fontsize=16)\n",
    "plt.xlabel('Cuisine Type', fontsize=12)\n",
    "plt.ylabel('Age Group', fontsize=12)\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35029a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by region and sum the DOW\n",
    "cuisine_by_region = df.groupby('customer_region')[dow_columns].sum()  \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cuisine_by_region, \n",
    "            annot=True,\n",
    "            annot_kws={'size': 10}, \n",
    "            cmap='PiYG', \n",
    "            fmt='.0f', \n",
    "            square=True)\n",
    "\n",
    "plt.title('DOW Activity by Region', fontsize=16)\n",
    "plt.xlabel('DOW', fontsize=12)  \n",
    "plt.ylabel('Region', fontsize=12)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28157c53",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e0e73",
   "metadata": {},
   "source": [
    "Payment Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cfd752-4005-40dc-a6c9-47ea5e10d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_counts = df.groupby(['age_group', 'payment_method']).size().unstack(fill_value=0)\n",
    "\n",
    "colors=['#87CEEB','#00BFFF','#4682B4']\n",
    "payment_counts.plot(kind='bar', \n",
    "                    stacked=False, \n",
    "                    figsize=(10, 6), \n",
    "                    color=colors, \n",
    "                    edgecolor='black') \n",
    "\n",
    "plt.title('Payment Methods by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Number of orders')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.legend(title='Payment Method')\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55419cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_counts_region = df.groupby(['customer_region', 'payment_method']).size().unstack(fill_value=0)\n",
    "\n",
    "colors=['#87CEEB','#00BFFF','#4682B4']\n",
    "payment_counts_region.plot(kind='bar', \n",
    "                    stacked=False, \n",
    "                    figsize=(10, 6), \n",
    "                    color=colors, \n",
    "                    edgecolor='black') \n",
    "\n",
    "plt.title('Payment Methods by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Number of orders')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.legend(title='Payment Method')\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f03a80",
   "metadata": {},
   "source": [
    "Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by region and age group\n",
    "age_counts = df.groupby(['customer_region', 'age_group']).size().reset_index(name='count')\n",
    "\n",
    "# Creating a pivot table\n",
    "pivot_age_counts = age_counts.pivot(index='customer_region', columns='age_group', values='count').fillna(0)\n",
    "\n",
    "# Plotting the stacked bar chart\n",
    "pivot_age_counts.plot(kind='bar', \n",
    "                      stacked=True, \n",
    "                      figsize=(10, 6), \n",
    "                      color=plt.cm.tab20.colors) # Ensuring the color palette is correct\n",
    "\n",
    "plt.title('Distribution of Age Groups by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.legend(title='Age Group', bbox_to_anchor=(1.05, 1), loc='upper left')  \n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cdb952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by city and age group\n",
    "age_counts_city = df.groupby(['customer_city', 'age_group']).size().reset_index(name='count')\n",
    "\n",
    "# Create the stacked bar plot\n",
    "age_counts_city_pivot = age_counts_city.pivot(index='customer_city', columns='age_group', values='count').fillna(0)\n",
    "\n",
    "age_counts_city_pivot.plot(kind='bar', \n",
    "                            stacked=True, \n",
    "                            figsize=(10, 6),\n",
    "                            color=plt.cm.tab20.colors) # Ensuring the color palette is correct\n",
    "plt.title('Distribution of Age Groups by City')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.legend(title='Age Group', bbox_to_anchor=(1.05, 1), loc='upper left')  \n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840f7caf",
   "metadata": {},
   "source": [
    "Cuisine Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe0354-02f4-4d33-937e-4f7469c316f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_counts = df.groupby('customer_region')[CUI_columns].sum().reset_index()\n",
    "\n",
    "cuisine_counts_ = cuisine_counts.melt(id_vars='customer_region', \n",
    "                                            value_vars=CUI_columns, \n",
    "                                            var_name='cuisine_type', \n",
    "                                            value_name='total_expenditure')\n",
    "\n",
    "top_cuisines = (\n",
    "    cuisine_counts_.groupby('customer_region')\n",
    "    .apply(lambda x: x.nlargest(3, 'total_expenditure'))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "top_cuisine_counts = top_cuisines.pivot(index='customer_region', \n",
    "                                        columns='cuisine_type', \n",
    "                                        values='total_expenditure').fillna(0)\n",
    "\n",
    "\n",
    "num_cuisines = top_cuisine_counts.shape[1]\n",
    "colors = plt.cm.Paired(np.linspace(0, 1, num_cuisines)) \n",
    "\n",
    "\n",
    "top_cuisine_counts.plot(kind='bar', \n",
    "                        stacked=True, \n",
    "                        figsize=(10, 6), \n",
    "                        color=colors)\n",
    "\n",
    "plt.title('Top 3 Cuisine Type by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Total Expenditure')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Type of Cuisine', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4809a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_counts = df.groupby('customer_city')[CUI_columns].sum().reset_index()\n",
    "\n",
    "cuisine_counts_1= cuisine_counts.melt(id_vars='customer_city', \n",
    "                                            value_vars=CUI_columns, \n",
    "                                            var_name='cuisine_type', \n",
    "                                            value_name='total_expenditure')\n",
    "\n",
    "top_cuisines = (\n",
    "    cuisine_counts_1.groupby('customer_city')\n",
    "    .apply(lambda x: x.nlargest(3, 'total_expenditure'))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "top_cuisine_counts = top_cuisines.pivot(index='customer_city', \n",
    "                                        columns='cuisine_type', \n",
    "                                        values='total_expenditure').fillna(0)\n",
    "\n",
    "\n",
    "num_cuisines = top_cuisine_counts.shape[1]\n",
    "colors = plt.cm.Paired(np.linspace(0, 1, num_cuisines)) \n",
    "\n",
    "\n",
    "top_cuisine_counts.plot(kind='bar', \n",
    "                        stacked=True, \n",
    "                        figsize=(10, 6), \n",
    "                        color=colors)\n",
    "\n",
    "plt.title('Top 3 Cuisine Type by City')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Total Expenditure')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Type of Cuisine', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df172147",
   "metadata": {},
   "source": [
    "Total Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cb5df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by region and sum the total spending\n",
    "region_spend = df.groupby('customer_region')['total_spend'].sum().reset_index()\n",
    "\n",
    "region_spend = region_spend.sort_values(by='total_spend', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='customer_region', y='total_spend', data=region_spend, palette=\"viridis\")\n",
    "\n",
    "plt.title(\"Total Spending per Region\")\n",
    "plt.xlabel(\"Customer Region\")\n",
    "plt.ylabel(\"Total Spend\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b689c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by age group and  total spending\n",
    "region_spend = df.groupby('age_group')['total_spend'].sum().reset_index()\n",
    "\n",
    "region_spend = region_spend.sort_values(by='total_spend', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='age_group', y='total_spend', data=region_spend, palette=\"viridis\")\n",
    "\n",
    "plt.title(\"Total Spending per Age Group\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Total Spend\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52dc18",
   "metadata": {},
   "source": [
    "Cuisine Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ece8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by region and cuisine diversity\n",
    "region_spend = df.groupby('customer_region')['cuisine_diversity'].sum().reset_index()\n",
    "\n",
    "region_spend = region_spend.sort_values(by='cuisine_diversity', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='customer_region', y='cuisine_diversity', data=region_spend, palette=\"viridis\")\n",
    "\n",
    "plt.title(\"Cuisine Diversity per Region\")\n",
    "plt.xlabel(\"Customer Region\")\n",
    "plt.ylabel(\"Cuisine Diveristy\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f51e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by age group and cuisine diversity\n",
    "region_spend = df.groupby('age_group')['cuisine_diversity'].sum().reset_index()\n",
    "\n",
    "region_spend = region_spend.sort_values(by='cuisine_diversity', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='age_group', y='cuisine_diversity', data=region_spend, palette=\"viridis\")\n",
    "\n",
    "plt.title(\"Cuisine Diversity per Age Group\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Cuisine Diversity\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40374dc9",
   "metadata": {},
   "source": [
    "3 Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbcf990-3dde-40db-965c-2b0f8aa777cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sum_of_orders']=df[['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']].sum(axis=1)\n",
    "# Group by customer_region and customer_age\n",
    "grouped = df.groupby(['customer_region', 'customer_age'])['sum_of_orders'].sum().reset_index()\n",
    "\n",
    "# Sort the results\n",
    "grouped = grouped.sort_values(['customer_region', 'customer_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949aab52-b803-4363-b461-c84ea3243423",
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_stats = grouped.groupby('customer_region').agg({\n",
    "    'customer_age': ['mean', 'min', 'max'],\n",
    "    'sum_of_orders': ['mean', 'min', 'max', 'sum']\n",
    "}).reset_index()\n",
    "\n",
    "print(regional_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02b2934-77bf-4d17-8d92-22c9ee8de91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a high-contrast color palette\n",
    "num_regions = len(grouped['customer_region'].unique())\n",
    "base_colors = plt.cm.get_cmap('Set1')(np.linspace(0, 1, num_regions))\n",
    "custom_colors = ['#FF1493', '#00FFFF', '#FFD700', '#32CD32', '#FF4500', '#8A2BE2', '#00CED1']\n",
    "color_palette = list(base_colors) + custom_colors\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, region in enumerate(grouped['customer_region'].unique()):\n",
    "    region_data = grouped[grouped['customer_region'] == region]\n",
    "    plt.scatter(region_data['customer_age'], region_data['sum_of_orders'], \n",
    "                label=region, alpha=0.6, color=color_palette[i])\n",
    "\n",
    "plt.xlabel('Customer Age', fontsize=12)\n",
    "plt.ylabel('Sum of Orders', fontsize=12)\n",
    "plt.title('Customer Age vs Sum of Orders by Region', fontsize=16)\n",
    "plt.legend(title='Region', title_fontsize='12', fontsize='10', loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0538066d-971a-4df6-a7e6-589068a66b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_colors = plt.get_cmap('tab20').colors  \n",
    "\n",
    "# cuisine_cols = all_cols = [col for col in df.columns if col.startswith('CUI_')]\n",
    "# all_cols.append(\"customer_region\")\n",
    "# all_cols.append(\"age_group\")\n",
    "# group_by_ageG_region_CUI =  df[all_cols].groupby(['customer_region','age_group']).sum()\n",
    "\n",
    "# group_by_ageG_region_CUI = (\n",
    "#     group_by_ageG_region_CUI\n",
    "#     .apply(lambda x: x.nlargest(5),axis=1)\n",
    "    \n",
    "# )\n",
    "\n",
    "# high_contrast_colors = [\n",
    "#     \"#000000\",  # Black\n",
    "#     \"#FF0000\",  # Red\n",
    "#     \"#00FFFF\",  # Cyan\n",
    "#     \"#00FF00\",  # Green\n",
    "#     \"#FF00FF\",  # Magenta\n",
    "#     \"#0000FF\",  # Blue\n",
    "#     \"#FFFF00\",  # Yellow\n",
    "#     \"#FFA500\",  # Orange\n",
    "#     \"#800080\",  # Purple\n",
    "#     \"#008080\",  # Teal\n",
    "#     \"#FF6347\",  # Tomato (bright red-orange)\n",
    "#     \"#40E0D0\",  # Turquoise\n",
    "#     \"#8B0000\",  # Dark Red\n",
    "#     \"#808080\",  # Gray\n",
    "#     \"#00008B\",  # Dark Blue\n",
    "#     \"#ADFF2F\"   # Green Yellow\n",
    "# ]\n",
    "# rows = math.ceil(len(df[\"customer_region\"].unique())/3)\n",
    "\n",
    "# fig, axes = plt.subplots(rows, 3, figsize=(15, 5 * rows))\n",
    "# axes = axes.flatten()  \n",
    "# for i,region in enumerate(df[\"customer_region\"].unique() ):\n",
    "#     # Filter data for the current customer_region\n",
    "#     region_data = group_by_ageG_region_CUI.loc[region]\n",
    "    \n",
    "#     # Plot\n",
    "#     region_data.plot(kind='bar',ax=axes[i], figsize=(30, 20), width=1,color=high_contrast_colors)\n",
    "#     axes[i].set_title(f'CUI by Age Group for Customer Region {region}')\n",
    "#     axes[i].set_xlabel('Age Group')\n",
    "#     axes[i].set_ylabel('Expenses')\n",
    "#     axes[i].tick_params(axis='x', rotation=0)  # Set x-axis label rotation\n",
    "\n",
    "#     axes[i].legend(title='CUI Type')\n",
    "    \n",
    "    \n",
    "# # Show the plot\n",
    "# for j in range(i + 1, len(axes)):\n",
    "#     axes[j].axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a0a91",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list_numerical = numerical_features + hr_columns + dow_columns + CUI_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers numerical features \n",
    "#computing the interquartile range \n",
    "q1= df[combined_list_numerical].quantile(0.25)\n",
    "q3=df[combined_list_numerical].quantile(0.75)\n",
    "iqr=q3-q1\n",
    "\n",
    "#compute the limits \n",
    "lower_lim= q1-(1.5*iqr)\n",
    "upper_lim=q3+(1.5*iqr)\n",
    "\n",
    "for feature in combined_list_numerical: \n",
    "    print(f\"{feature:<25} Lower Limit:{lower_lim[feature]:>10}      Upper Limit:{upper_lim[feature]:>10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cbceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers(df, list, lower_lim, upper_lim):\n",
    "    outliers = {}\n",
    "    obvious_outliers = []\n",
    "\n",
    "    for metric in combined_list_numerical:\n",
    "        if metric not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        if metric not in lower_lim.keys() or metric not in upper_lim.keys():\n",
    "            continue\n",
    "        \n",
    "        outliers[metric] = []\n",
    "        llim = lower_lim[metric]\n",
    "        ulim = upper_lim[metric]\n",
    "        \n",
    "        for i, value in enumerate(df[metric]):\n",
    "            if pd.isna(value):\n",
    "                continue\n",
    "            \n",
    "            if value < llim or value > ulim:\n",
    "                outliers[metric].append(value)\n",
    "        \n",
    "        print(f\"Total outliers in {metric}: {len(outliers[metric])}\")\n",
    "\n",
    "    # Check for observations that are outliers in all features (Obvious Outliers)\n",
    "    for index, row in df.iterrows():\n",
    "        is_global_outlier = True\n",
    "        for metric in combined_list_numerical:\n",
    "            if metric not in df.columns or metric not in lower_lim or metric not in upper_lim:\n",
    "                is_global_outlier = False\n",
    "                break\n",
    "            \n",
    "            value = row[metric]\n",
    "            if pd.isna(value):\n",
    "                is_global_outlier = False\n",
    "                break\n",
    "            \n",
    "            llim = lower_lim[metric]\n",
    "            ulim = upper_lim[metric]\n",
    "            \n",
    "            if llim <= value <= ulim:\n",
    "                is_global_outlier = False\n",
    "                break\n",
    "        \n",
    "        if is_global_outlier:\n",
    "            obvious_outliers.append(index)\n",
    "    print(\"-----------------------------\")\n",
    "    print(f\"Total global outliers: {len(obvious_outliers)}\")\n",
    "    return outliers, obvious_outliers\n",
    "    \n",
    "    \n",
    "outliers, obvious_outliers = identify_outliers(df, combined_list_numerical, lower_lim, upper_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8798c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list_numerical_ = [col for col in combined_list_numerical if col not in ['first_order', 'last_order']]\n",
    "\n",
    "outliers, obvious_outliers = identify_outliers(df, combined_list_numerical_, lower_lim, upper_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff06c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter that will verify if an observation has every characteristic in the Interquartile Range or not \n",
    "filters_iqr = []                                            \n",
    "for metric in combined_list_numerical:\n",
    "    llim = lower_lim[metric]\n",
    "    ulim = upper_lim[metric]\n",
    "    filters_iqr.append(df[metric].between(llim, ulim, inclusive='neither'))\n",
    "\n",
    "filters_iqr_all = pd.concat(filters_iqr, axis=1).all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ca1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf0ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_iqr_all  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926fbe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df[filters_iqr_all] == 'False'])      #These are the features that have at least one of its characteristics considered as an outlier (out of the IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6019904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iqr = df[filters_iqr_all]\n",
    "print('Percentage of data kept after removing outliers:', 100*(np.round(df_iqr.shape[0] / df.shape[0], decimals=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df0105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_man = (\n",
    "     (df['customer_age']<=50)  #justificar o 50 \n",
    "    &\n",
    "    (df['vendor_count']<=30)\n",
    "    &\n",
    "    (df['product_count']<=100)\n",
    "    &\n",
    "    (df['HR_0']<=9)\n",
    "    &\n",
    "    (df['HR_1']<=9)\n",
    "    &\n",
    "    (df['HR_2']<=10)  \n",
    "    &\n",
    "    (df['HR_3']<=10) \n",
    "    &\n",
    "    (df['HR_4']<=10) \n",
    "    &\n",
    "    (df['HR_5']<=5) \n",
    "    &\n",
    "    (df['HR_6']<=8) \n",
    "    &\n",
    "    (df['HR_7']<=9) \n",
    "    &\n",
    "    (df['HR_8']<=12) \n",
    "    &\n",
    "    (df['HR_9']<=11) \n",
    "    &\n",
    "    (df['HR_10']<=17) \n",
    "    &\n",
    "    (df['HR_11']<=17) \n",
    "    &\n",
    "    (df['HR_12']<=17) \n",
    "    &\n",
    "    (df['HR_13']<=12) \n",
    "    &\n",
    "    (df['HR_14']<=11) \n",
    "    &\n",
    "    (df['HR_15']<=10) \n",
    "    &\n",
    "    (df['HR_16']<=14) \n",
    "    &\n",
    "    (df['HR_17']<=15) \n",
    "    &\n",
    "    (df['HR_18']<=20) \n",
    "    &\n",
    "    (df['HR_19']<=16) \n",
    "    &\n",
    "    (df['HR_20']<=15) \n",
    "    &\n",
    "    (df['HR_21']<=6) \n",
    "    &\n",
    "    (df['HR_22']<=7) \n",
    "    &\n",
    "    (df['HR_23']<=6) \n",
    "    &\n",
    "    (df['CUI_American']<=150)\n",
    "    &\n",
    "    (df['CUI_Asian']<=400)\n",
    "    &\n",
    "    (df['CUI_Beverages']<=150)  \n",
    "    &\n",
    "    (df['CUI_Cafe']<=150) \n",
    "    &\n",
    "    (df['CUI_Chicken Dishes']<=75) \n",
    "    &\n",
    "    (df['CUI_Chinese']<=200) \n",
    "    &\n",
    "    (df['CUI_Desserts']<=130) \n",
    "    &\n",
    "    (df['CUI_Healthy']<=150) \n",
    "    &\n",
    "    (df['CUI_Indian']<=150) \n",
    "    &\n",
    "    (df['CUI_Italian']<=200) \n",
    "    &\n",
    "    (df['CUI_Japanese']<=200) \n",
    "    &\n",
    "    (df['CUI_Noodle Dishes']<=100) \n",
    "    &\n",
    "    (df['CUI_OTHER']<=100) \n",
    "    &\n",
    "    (df['CUI_Street Food / Snacks']<=200) \n",
    "    &\n",
    "    (df['CUI_Thai']<=60)\n",
    "    & \n",
    "    (df['Sunday']<=12)\n",
    "    &\n",
    "    (df['Monday']<=13)\n",
    "    &\n",
    "    (df['Tuesday']<=14)  \n",
    "    &\n",
    "    (df['Wednesday']<=15) \n",
    "    &\n",
    "    (df['Thursday']<=16) \n",
    "    &\n",
    "    (df['Friday']<=15) \n",
    "    &\n",
    "    (df['Saturday']<=15)  \n",
    ")\n",
    "\n",
    "df_outliers = df[filters_man]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of data kept after removing outliers:', 100*(np.round(df_outliers.shape[0] / df.shape[0], decimals=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb9f51",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c58e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480af3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['customer_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohc = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f84c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_new = ['last_promo', 'payment_method', 'age_group', 'is_chain', 'customer_city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb7d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'age_group' from the list of categorical features\n",
    "columns_to_remove = ['age_group', 'last_promo']  \n",
    "cf_for_ohc = [col for col in categorical_features_new if col not in columns_to_remove]\n",
    "\n",
    "# Initialize the encoder with the chosen settings\n",
    "ohc = OneHotEncoder(sparse_output=False, drop=None)\n",
    "\n",
    "# Fit the encoder on the selected categorical features\n",
    "ohc.fit(df_ohc[cf_for_ohc])\n",
    "\n",
    "# Transform the selected categorical features\n",
    "ohc_features = ohc.transform(df_ohc[cf_for_ohc])\n",
    "\n",
    "# Create a DataFrame with encoded feature names\n",
    "ohc_df = pd.DataFrame(\n",
    "    ohc_features,\n",
    "    index=df_ohc.index,\n",
    "    columns=ohc.get_feature_names_out(cf_for_ohc)\n",
    ")\n",
    "\n",
    "# Concatenate the encoded features back to the original dataset\n",
    "ohc_encoded = pd.concat(\n",
    "    [df_ohc.drop(columns=cf_for_ohc), ohc_df],\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7b6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohc_encoded.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958ad659",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohc_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5418a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Define the encoder with explicit categories\n",
    "ordinal_encoder = OrdinalEncoder(\n",
    "    categories=[['Teenagers (15-19)', 'Young Adults (20-29)', 'Adults (30-49)', 'Middle-aged (50-64)', 'Seniors (65-80)']],\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-1  # Use -1 for unknown categories\n",
    ")\n",
    "\n",
    "# Ensure the 'age_group' column exists\n",
    "if 'age_group' not in df_ohc.columns:\n",
    "    raise KeyError(\"The column 'age_group' is not in the DataFrame.\")\n",
    "\n",
    "# Fit and transform the data\n",
    "try:\n",
    "    df_ohc['age_group_encoded'] = ordinal_encoder.fit_transform(df_ohc[['age_group']])\n",
    "except Exception as e:\n",
    "    print(f\"Error during encoding: {e}\")\n",
    "\n",
    "# Verify the transformed column\n",
    "print(df_ohc[['age_group', 'age_group_encoded']].head())\n",
    "\n",
    "# Concatenate with the existing DataFrame\n",
    "df_encoded = pd.concat([ohc_encoded, df_ohc[['age_group_encoded']]], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the PROMO feature to binary values\n",
    "promo_mapping = {\n",
    "    'N0 PROMO': 0,  # No promo maps to 0\n",
    "    'DISCOUNT': 1,   # All promos map to 1\n",
    "    'DELIVERY': 1,\n",
    "    'FREEBIE': 1\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the binary encoded column\n",
    "df_ohc['last_promo'] = df_ohc['last_promo'].map(promo_mapping)\n",
    "\n",
    "# Concatenate the encoded features back to the original dataset\n",
    "df_encoded = pd.concat([ohc_encoded, df_ohc['last_promo']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44c6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.drop(columns=['age_group'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
