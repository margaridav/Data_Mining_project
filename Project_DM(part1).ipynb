{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee3aa48",
   "metadata": {},
   "source": [
    "# Data Mining Project - ABCDEatsInc.\n",
    "\n",
    "**Group 16 members:** <br>\n",
    "- Ana Margarida Valente, 20240936 <br>\n",
    "- Catarina Carneiro, 20240690 <br>\n",
    "- Rui Reis, 20240854 <br>\n",
    "- Mara Mesquita, 20241039 <br>\n",
    "\n",
    "**MSc:** Data Science and Advanced Analytics - Nova IMS <br>\n",
    "**Course:** Data Mining <br>\n",
    "2024/2025\n",
    "\n",
    "## Introduction\n",
    "The client, \"ABCDEatsInc.\", a fictional food delivery service partnering with a range of restaurants to offer diverse meal options, aims to gain a deeper understanding of its customers' behaviors by identifying distinct segments within its database through customer segmentation. A dataset containing data collected over three months from three cities was provided to define, describe, and analyze the resulting clusters. The goal is to uncover actionable insights and briefly recommend marketing strategies tailored to each segment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673f250",
   "metadata": {},
   "source": [
    "## Variables:\n",
    "- customer_id: Unique identifier for each customer.\n",
    "- customer_region: Geographic region where the customer is located.\n",
    "- customer_age: Age of the customer.\n",
    "- vendor_count: Number of unique vendors the customer has ordered from.\n",
    "- product_count: Total number of products the customer has ordered.\n",
    "- is_chain: Indicates whether the customerâ€™s order was from a chain restaurant.\n",
    "- first_order: Number of days from the start of the dataset when the customer first placed an order.\n",
    "- last_order: Number of days from the start of the dataset when the customer most recently placed an order.\n",
    "- last_promo: The category of the promotion or discount most recently used by the customer.\n",
    "- payment_method: Method most recently used by the customer to pay for their orders.\n",
    "- CUI_American,CUI_Asian,CUI_Chinese,CUI_Italian, etc.: The amount in monetary units spent by the customer from the indicated type of cuisine.\n",
    "- DOW_0 to DOW_6: Number of orders placed on each day of the week (0 = Sunday, 6 = Saturday).\n",
    "- HR_0 to HR_23: Number of orders placed during each hour of the day (0 = midnight, 23 = 11 PM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590ffd3",
   "metadata": {},
   "source": [
    "# Table of Contents !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c76c2a3",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"import\">\n",
    "\n",
    "## 1. Import \n",
    "    \n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8facac19",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"libraries\">\n",
    "\n",
    "## 1.1 Import libraries\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "893620af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "\n",
    "from itertools import product\n",
    "from scipy.stats import skewnorm\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# for better resolution plots\n",
    "%config InlineBackend.figure_format = 'retina' # optionally, you can change 'svg' to 'retina'\n",
    "\n",
    "# Setting seaborn style\n",
    "sns.set()\n",
    "\n",
    "# Display all the df and results\n",
    "pd.set_option('display.max_rows', None)  \n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.width', 1000)  \n",
    "pd.set_option('display.colheader_justify', 'center')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f2d93c",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"dataset\">\n",
    "\n",
    "## 1.2 Import the dataset\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1dd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv(\"DM2425_ABCDEats_DATASET.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "289c78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a backup of the original df\n",
    "df_backup=df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a7fa39",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"exploration\">\n",
    "\n",
    "# 2. Data Exploration\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378370a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"general\">\n",
    "\n",
    "## 2.1 General Data Analysis\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0606dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d71a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1049e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check columns\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Data Types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1249533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics of the Categorical variables\n",
    "df.describe(include='O').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d3a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Statistics of the Numerical variables\n",
    "df.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cdf73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicates\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fe872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the % of the missing values:\n",
    "missing_percentage = (df.isnull().mean() * 100).sort_values(ascending=False)\n",
    "\n",
    "print(\"Percentage of Missing Values:\")\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8659ab83",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"treat\">\n",
    "\n",
    "## 2.2 Data Treatment\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a128fa8",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"rename\">\n",
    "\n",
    "### 2.2.1 Rename Columns\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec51e9",
   "metadata": {},
   "source": [
    "- Change the DOW columns to the days of the week names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01b386c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.rename(columns={'DOW_0':'Sunday', 'DOW_1':'Monday', 'DOW_2':'Tuesday', 'DOW_3':'Wednesday', 'DOW_4':'Thursday', 'DOW_5':'Friday','DOW_6':'Saturday'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb53b8a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"types\">\n",
    "\n",
    "### 2.2.2 Data Types\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62399ef6",
   "metadata": {},
   "source": [
    "- customer_age -> float? (change to int)\n",
    "- first_order -> float? (change to int)\n",
    "- HR_0 -> float? (change to int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be99279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_age'] = df['customer_age'].astype('Int64')\n",
    "df['first_order'] = df['first_order'].astype('Int64')\n",
    "df['HR_0'] = df['HR_0'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d71f09",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"nan\">\n",
    "\n",
    "### 2.2.3 Missing Values\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd39972",
   "metadata": {},
   "source": [
    "**Missing Values : HR_0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bb9312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Check when HR_0 = NaN, which is the variable with most missing values\n",
    "# nan_HR_0 = df[df['HR_0'].isna()]\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# nan_HR_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "409cbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the columns of the DOW and the HR columns\n",
    "dow_columns = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "hr_columns = [col for col in df.columns if col.startswith('HR_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b62b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To replace the NaN's of HR_0, let's compare the sum of orders of the DOW with the sum of orders of the HR:\n",
    "#If it's the same, then HR_0 should be 0, if not, it's the difference between the 2 values, since the sum should be equal\n",
    "\n",
    "row_sum_dow = df[dow_columns].sum(axis=1)\n",
    "row_sum_hr = df[hr_columns].sum(axis=1)\n",
    "\n",
    "row_difference = row_sum_dow - row_sum_hr\n",
    "\n",
    "df.loc[df['HR_0'].isna(), 'HR_0'] = row_difference\n",
    "\n",
    "df['HR_0'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19785329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HR_0'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4eaf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the sum of the DOW is equal to the sum of the Hours; It must be\n",
    "check = (df[dow_columns].sum(axis=1) == df[hr_columns].sum(axis=1)).all()\n",
    "\n",
    "if check:\n",
    "    print(\"Yes\")\n",
    "else:\n",
    "    print(\"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e108b30",
   "metadata": {},
   "source": [
    "**Missing Values : first_order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "116f6182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Check when first_order = NaN\n",
    "# nan_first_order = df[df['first_order'].isna()]\n",
    "# nan_first_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f89c851",
   "metadata": {},
   "source": [
    "It seem that when the first_order is a missing value, the last_order = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dd1a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['first_order'].isna() & (df['last_order'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde9842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we are checking to see if in this situation, there was only one order placed\n",
    "check = (df[df['first_order'].isna() & (df['last_order'] == 0)][dow_columns].sum(axis=1) == 1).all()\n",
    "\n",
    "if check:\n",
    "    print(\"All rows have row_sum_dow equal to 1 (indicating only one order).\")\n",
    "else:\n",
    "    print(\"There are rows where row_sum_dow is not 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32269ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check which rows do not meet the condition\n",
    "non_matching_rows = df[(df['first_order'].isna() & (df['last_order'] == 0)) & (df[dow_columns].sum(axis=1) != 1)]\n",
    "\n",
    "non_matching_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1fdd40",
   "metadata": {},
   "source": [
    "There are only 2 cases that do not meet the condition. Both cases show that the 2 orders were placed on the same day (Saturday). \n",
    "\n",
    "Based on the previous analysis, we will assume that when first_order is missing it should be replaced with 0, ensuring that both first_order and last_order occur on the same day (the day the dataset begun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0668039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_order is missing only when last_order = 0\n",
    "#first_order cannot happen after last_order. So we will set the missing first_order values to 0\n",
    "df.loc[df['first_order'].isna() & (df['last_order'] == 0), 'first_order'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a80e1e",
   "metadata": {},
   "source": [
    "**Missing Values : customer_age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "065fcec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if there are any missing values\n",
    "# if df['customer_age'].isnull().any():\n",
    "    \n",
    "#     missing_values_before = df.loc[df['customer_age'].isnull(), ['customer_age']].copy()\n",
    "\n",
    "\n",
    "#     imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "\n",
    "    \n",
    "#     df['customer_age'] = imputer.fit_transform(df[['customer_age']])\n",
    "\n",
    "#     df['customer_age'] = df['customer_age'].round().astype(int)\n",
    "\n",
    "#     # Create a DataFrame to compare the original values (NaN) with the imputed values\n",
    "#     comparison = pd.DataFrame({\n",
    "#         'Original_Index': missing_values_before.index,\n",
    "#         'Original_Value': missing_values_before['customer_age'].values,\n",
    "#         'Imputed_Value': df['customer_age'].loc[missing_values_before.index].values\n",
    "#     })\n",
    "\n",
    "#     print(comparison)\n",
    "# else:\n",
    "#     print(\"No missing values found in 'customer_age'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6aff99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Check when customer_age = NaN\n",
    "# nan_customer_age = df[df['customer_age'].isna()]\n",
    "# nan_customer_age\n",
    "\n",
    "# #Replace the missing values with the mean or median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7c6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['customer_age'].dropna(), bins=30, edgecolor='black')  \n",
    "plt.title('Histogram of Age')\n",
    "plt.xlabel('Age') \n",
    "plt.ylabel('Frequency') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6983a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the histogram is skewed, the median is preferred to replace the missing values\n",
    "median_age = df['customer_age'].median()\n",
    "df['customer_age'] = df['customer_age'].fillna(median_age)\n",
    "print(f\"Median = {median_age}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f334baa",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"duplicates\">\n",
    "\n",
    "### 2.2.4 Check for Duplicates\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09595ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd697d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ea52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#% of duplicates:\n",
    "df.duplicated().mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bdc202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify customer_id duplicated (it should be a unique value, since it represents 1 customer)\n",
    "duplicate_values = df['customer_id'].value_counts()[df['customer_id'].value_counts() > 1]\n",
    "\n",
    "duplicate_rows = df[df['customer_id'].isin(duplicate_values.index)]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f'Total: {len(duplicate_rows)}') \n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fe9cb5",
   "metadata": {},
   "source": [
    "The duplicates are only the cases where the customer_id is duplicated, meaning that are 2 entries of the same customer in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d73d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fedbe1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49948e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46eef93",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"uniqueandstrange\">\n",
    "\n",
    "### 2.2.5 Check Unique and Strange values\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1229f5df",
   "metadata": {},
   "source": [
    "**Vendor_count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba890a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vendor_count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c98880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['vendor_count'] == 41]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f4018",
   "metadata": {},
   "source": [
    "**Product_count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a600fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['product_count'] == 269]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837bd30f",
   "metadata": {},
   "source": [
    "**Customer_region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3fd670",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df[df['customer_region'] == '-']) / len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "388a085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '-' with the mode\n",
    "mode_value = df['customer_region'].mode()[0]  \n",
    "\n",
    "df['customer_region'] = df['customer_region'].replace('-', mode_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6d66e9",
   "metadata": {},
   "source": [
    "- '-' -> Strange = 1,386%; Assuming it's a missing value and Use Mode\n",
    "- There are 3 cities, aggregate the cities by the first number of the region (2,4,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2f9f8",
   "metadata": {},
   "source": [
    "**Customer_age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe3ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb44d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['customer_age'] == 15) | (df['customer_age'] == 16)| (df['customer_age'] == 17)]\n",
    "#It could be a problem since it's a minor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd7003",
   "metadata": {},
   "source": [
    "**last_promo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_promo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162e0e8",
   "metadata": {},
   "source": [
    "- '-' -> Changing to 'NO PROMO', to be more perceptible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4cb58dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_promo'] = df['last_promo'].replace('-', 'NO PROMO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990879d3",
   "metadata": {},
   "source": [
    "**Payment_method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab28ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['payment_method'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746741cb",
   "metadata": {},
   "source": [
    "**First_order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d4f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_order'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_order'].max()\n",
    "#Makes sense because the dataset is from a three-month period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55472103",
   "metadata": {},
   "source": [
    "**Last_order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead55e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_order'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2bd685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_order'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0786324d",
   "metadata": {},
   "source": [
    "**is_chain**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672cc276",
   "metadata": {},
   "source": [
    "This variable needs to be fixed. The metadata does not correspond to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db9b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_chain'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d226cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the orders are on bevarages\n",
    "df[df['is_chain'] == 83]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bcba8a",
   "metadata": {},
   "source": [
    "Change the is_chain variable to Binary Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ec285b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "df['is_chain'] = (df['is_chain'] > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375437c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_chain']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce03f4a",
   "metadata": {},
   "source": [
    "**DOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3552f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in dow_columns:\n",
    "#     unique_values = df[column].unique()  # Get unique values\n",
    "#     print(f\"Column: {column}\")\n",
    "#     print(f\"Unique Values: {unique_values}\")\n",
    "#     print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043a628d",
   "metadata": {},
   "source": [
    "**Hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fa358ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in hr_columns:\n",
    "#     unique_values = df[column].unique()  # Get unique values\n",
    "#     print(f\"Column: {column}\")\n",
    "#     print(f\"Unique Values: {unique_values}\")\n",
    "#     print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8eb8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['HR_8'] == 52] #Almost every purchase was on Beverages (possibly for breakfast?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb63c4a",
   "metadata": {},
   "source": [
    "**Cuisine Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "262150ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     if col.startswith('CUI_'):\n",
    "#         unique_values = df[col].unique()  \n",
    "#         print(f\"Column: {col}\")\n",
    "#         print(f\"Unique Values: {unique_values}\")\n",
    "#         print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2fa4d8",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"visual\">\n",
    "\n",
    "# 3. Data Visualization\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d6538",
   "metadata": {},
   "source": [
    " Define Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e278aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features=['customer_age', 'vendor_count','product_count', 'first_order', 'last_order']\n",
    "categorical_features=['customer_region','last_promo','payment_method','is_chain']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5ec840",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"num\">\n",
    "\n",
    "## 3.1 Numerical Features\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9aa643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_outliers(data):\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_lim = Q1 - 1.5 * IQR\n",
    "    upper_lim = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data < lower_lim) | (data > upper_lim)]\n",
    "    percentage = (len(outliers) / len(data)) * 100  \n",
    "    return len(outliers), percentage, lower_lim, upper_lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_features:\n",
    "    print(f\" Statistics for column: {col}\")\n",
    "    \n",
    "    # Calculate key statistics\n",
    "    mean = df[col].mean()\n",
    "    median = df[col].median()\n",
    "    std_dev = df[col].std()\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    skewness = df[col].skew()\n",
    "    kurtosis = df[col].kurt()\n",
    "\n",
    "    # Display the statistics\n",
    "    print(f'  Mean: {mean:.2f}')\n",
    "    print(f'  Median: {median:.2f}')\n",
    "    print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "    print(f'  Min: {min_val}')\n",
    "    print(f'  Max: {max_val}')\n",
    "    print(f'  Skewness: {skewness:.2f}')\n",
    "    print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "    print('-' * 50 )\n",
    "    \n",
    "    # Visualization of each Variable:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df[col], kde=True, color='steelblue')\n",
    "    plt.title(f'Histogram of {col}')\n",
    "\n",
    "    # Boxplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(y=df[col], color='steelblue')\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "\n",
    "    #set fixed scale between -10 and 100 (to analyse better the outliers)\n",
    "    plt.ylim(-10,100)\n",
    "\n",
    "    # Analyze outliers for the numerical variables\n",
    "    outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "    print(f'Count of outliers: {outlier_count}')\n",
    "    print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "    print(f'Lower Lim:{lower_lim}')\n",
    "    print(f'Upper Lim:{upper_lim}')\n",
    "    print('-' * 40)\n",
    "   \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e93f8ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cui_bx=['CUI_American', 'CUI_Asian', 'CUI_Beverages','CUI_Cafe', 'CUI_Chicken Dishes', \n",
    "#         'CUI_Chinese', 'CUI_Desserts','CUI_Healthy', 'CUI_Indian', 'CUI_Italian', \n",
    "#         'CUI_Japanese','CUI_Noodle Dishes', 'CUI_OTHER', 'CUI_Street Food / Snacks','CUI_Thai']\n",
    "\n",
    "# for col in cui_bx:\n",
    "#     print(f\" Statistics for column: {col}\")\n",
    "    \n",
    "#     # Calculate key statistics\n",
    "#     mean = df[col].mean()\n",
    "#     median = df[col].median()\n",
    "#     std_dev = df[col].std()\n",
    "#     min_val = df[col].min()\n",
    "#     max_val = df[col].max()\n",
    "#     skewness = df[col].skew()\n",
    "#     kurtosis = df[col].kurt()\n",
    "\n",
    "#     # Display the statistics\n",
    "#     print(f'  Mean: {mean:.2f}')\n",
    "#     print(f'  Median: {median:.2f}')\n",
    "#     print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "#     print(f'  Min: {min_val}')\n",
    "#     print(f'  Max: {max_val}')\n",
    "#     print(f'  Skewness: {skewness:.2f}')\n",
    "#     print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "#     print('-' * 50 )\n",
    "    \n",
    "#     # Visualization of each Variable:\n",
    "#     plt.figure(figsize=(12, 5))\n",
    "\n",
    "#     # Histogram\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     sns.histplot(df[col], kde=True, color='steelblue')\n",
    "#     plt.title(f'Histogram of {col}')\n",
    "\n",
    "#     # Boxplot\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     sns.boxplot(y=df[col], color='steelblue')\n",
    "#     plt.title(f'Boxplot of {col}')\n",
    "\n",
    "#     #set fixed scale between -10 and 250 (to analyse better the outliers)\n",
    "#     plt.ylim(-10, 250)\n",
    "\n",
    "#     # Analyze outliers for the numerical variables\n",
    "#     outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "#     print(f'Count of outliers: {outlier_count}')\n",
    "#     print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "#     print(f'Lower Lim:{lower_lim}')\n",
    "#     print(f'Upper Lim:{upper_lim}')\n",
    "#     print('-' * 40)\n",
    "   \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb5c39a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hr_bx= ['HR_0', 'HR_1', 'HR_2', 'HR_3', 'HR_4', 'HR_5','HR_6', 'HR_7', 'HR_8', 'HR_9', 'HR_10', \n",
    "#         'HR_11', 'HR_12', 'HR_13','HR_14', 'HR_15', 'HR_16', 'HR_17', 'HR_18', 'HR_19', 'HR_20', 'HR_21','HR_22', 'HR_23']\n",
    "\n",
    "# for col in hr_bx:\n",
    "#     print(f\" Statistics for column: {col}\")\n",
    "    \n",
    "#     # Calculate key statistics\n",
    "#     mean = df[col].mean()\n",
    "#     median = df[col].median()\n",
    "#     std_dev = df[col].std()\n",
    "#     min_val = df[col].min()\n",
    "#     max_val = df[col].max()\n",
    "#     skewness = df[col].skew()\n",
    "#     kurtosis = df[col].kurt()\n",
    "\n",
    "#     # Display the statistics\n",
    "#     print(f'  Mean: {mean:.2f}')\n",
    "#     print(f'  Median: {median:.2f}')\n",
    "#     print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "#     print(f'  Min: {min_val}')\n",
    "#     print(f'  Max: {max_val}')\n",
    "#     print(f'  Skewness: {skewness:.2f}')\n",
    "#     print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "#     print('-' * 50 )\n",
    "    \n",
    "#     # Visualization of each Variable:\n",
    "#     plt.figure(figsize=(12, 5))\n",
    "\n",
    "#     # Histogram\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     sns.histplot(df[col], kde=True, color='steelblue')\n",
    "#     plt.title(f'Histogram of {col}')\n",
    "\n",
    "#     # Boxplot\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     sns.boxplot(y=df[col], color='steelblue')\n",
    "#     plt.title(f'Boxplot of {col}')\n",
    "\n",
    "#     #set fixed scale between -10 and 20 (to analyse better the outliers)\n",
    "#     plt.ylim(-10,20)\n",
    "    \n",
    "#     # Analyze outliers for the numerical variables\n",
    "#     outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "#     print(f'Count of outliers: {outlier_count}')\n",
    "#     print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "#     print(f'Lower Lim:{lower_lim}')\n",
    "#     print(f'Upper Lim:{upper_lim}')\n",
    "#     print('-' * 40)\n",
    "   \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b04eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dow_bx=['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday','Friday', 'Saturday']\n",
    "\n",
    "# for col in dow_bx:\n",
    "#     print(f\" Statistics for column: {col}\")\n",
    "    \n",
    "#     # Calculate key statistics\n",
    "#     mean = df[col].mean()\n",
    "#     median = df[col].median()\n",
    "#     std_dev = df[col].std()\n",
    "#     min_val = df[col].min()\n",
    "#     max_val = df[col].max()\n",
    "#     skewness = df[col].skew()\n",
    "#     kurtosis = df[col].kurt()\n",
    "\n",
    "#     # Display the statistics\n",
    "#     print(f'  Mean: {mean:.2f}')\n",
    "#     print(f'  Median: {median:.2f}')\n",
    "#     print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "#     print(f'  Min: {min_val}')\n",
    "#     print(f'  Max: {max_val}')\n",
    "#     print(f'  Skewness: {skewness:.2f}')\n",
    "#     print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "#     print('-' * 50 )\n",
    "    \n",
    "#     # Visualization of each Variable:\n",
    "#     plt.figure(figsize=(12, 5))\n",
    "\n",
    "#     # Histogram\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     sns.histplot(df[col], kde=True, color='steelblue')\n",
    "#     plt.title(f'Histogram of {col}')\n",
    "\n",
    "#     # Boxplot\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     sns.boxplot(y=df[col], color='steelblue')\n",
    "#     plt.title(f'Boxplot of {col}')\n",
    "\n",
    "#     #set fixed scale between -10 and 20 (to analyse better the outliers)\n",
    "#     plt.ylim(-10, 20)\n",
    "\n",
    "#     # Analyze outliers for the numerical variables\n",
    "#     outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "#     print(f'Count of outliers: {outlier_count}')\n",
    "#     print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "#     print(f'Lower Lim:{lower_lim}')\n",
    "#     print(f'Upper Lim:{upper_lim}')\n",
    "#     print('-' * 40)\n",
    "   \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fd8e61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define groups of columns of the same category\n",
    "dow_columns = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "hr_columns = [col for col in df.columns if col.startswith('HR_')]\n",
    "CUI_columns = [col for col in df.columns if col.startswith('CUI_')]\n",
    "#Define the sum of the columns\n",
    "DOW_counts = df[dow_columns].sum()\n",
    "HR_counts = df[hr_columns].sum()\n",
    "CUI_counts = df[CUI_columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "DOW_counts.plot(kind='bar', \n",
    "                color='steelblue', \n",
    "                edgecolor='black')\n",
    "\n",
    "plt.title('Number of Orders for Each Day of the Week')\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ccac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "HR_counts.plot(kind='bar', \n",
    "               color='steelblue', \n",
    "               edgecolor='black')\n",
    "\n",
    "plt.title('Number of Orders for Each Hour')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d7249",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUI_counts_sorted = CUI_counts.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "CUI_counts_sorted.plot(kind='bar', \n",
    "                       color='steelblue', \n",
    "                       edgecolor='black')\n",
    "\n",
    "plt.title('Expenses for each Type of Cuisine')\n",
    "plt.xlabel('Type of Cuisine')\n",
    "plt.ylabel('Expenses')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff241649",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars= numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a2111",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df['vendor_count'], y=df['product_count'], color='steelblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b719b",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cat\">\n",
    "\n",
    "## 3.2 Categorical Features\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d987e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_features:\n",
    "    print(f\"Analysis for categorical column: {col}\")\n",
    "    \n",
    "    # Calculate frequency counts\n",
    "    freq_counts = df[col].value_counts()\n",
    "    \n",
    "    # Display the frequency counts\n",
    "    print(\"Frequency counts:\")\n",
    "    print(freq_counts)\n",
    "    print(\"-\"*50 )\n",
    "    \n",
    "    # Visualization for categorical variables:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(x=df[col], palette='tab10')\n",
    "    plt.title(f'Count Plot of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c59440",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"out\">\n",
    "\n",
    "# 4. Outliers\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2f5dc",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"outanalysis\">\n",
    "\n",
    "## 4.1 Analysis\n",
    "    \n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f64fff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define groups of columns of the same category\n",
    "dow_columns = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "hr_columns = [col for col in df.columns if col.startswith('HR_')]\n",
    "CUI_columns = [col for col in df.columns if col.startswith('CUI_')]\n",
    "\n",
    "#Define the sum of the columns\n",
    "DOW_counts = df[dow_columns].sum()\n",
    "HR_counts = df[hr_columns].sum()\n",
    "CUI_counts = df[CUI_columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea0457fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list_numerical = numerical_features + hr_columns + dow_columns + CUI_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da09f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the interquartile range \n",
    "q1= df[combined_list_numerical].quantile(0.25)\n",
    "q3=df[combined_list_numerical].quantile(0.75)\n",
    "iqr=q3-q1\n",
    "\n",
    "#compute the limits \n",
    "lower_lim= q1-(1.5*iqr)\n",
    "upper_lim=q3+(1.5*iqr)\n",
    "\n",
    "for feature in combined_list_numerical: \n",
    "    print(f\"{feature:<25} Lower Limit:{lower_lim[feature]:>10}      Upper Limit:{upper_lim[feature]:>10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b25bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers(df, list, lower_lim, upper_lim):\n",
    "    outliers = {}\n",
    "    obvious_outliers = []\n",
    "\n",
    "    for metric in combined_list_numerical:\n",
    "        if metric not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        if metric not in lower_lim.keys() or metric not in upper_lim.keys():\n",
    "            continue\n",
    "        \n",
    "        outliers[metric] = []\n",
    "        llim = lower_lim[metric]\n",
    "        ulim = upper_lim[metric]\n",
    "        \n",
    "        for i, value in enumerate(df[metric]):\n",
    "            if pd.isna(value):\n",
    "                continue\n",
    "            \n",
    "            if value < llim or value > ulim:\n",
    "                outliers[metric].append(value)\n",
    "        \n",
    "        print(f\"Total outliers in {metric}: {len(outliers[metric])}\")\n",
    "\n",
    "    # Check for observations that are outliers in all features (Obvious Outliers)\n",
    "    for index, row in df.iterrows():\n",
    "        is_global_outlier = True\n",
    "        for metric in combined_list_numerical:\n",
    "            if metric not in df.columns or metric not in lower_lim or metric not in upper_lim:\n",
    "                is_global_outlier = False\n",
    "                break\n",
    "            \n",
    "            value = row[metric]\n",
    "            if pd.isna(value):\n",
    "                is_global_outlier = False\n",
    "                break\n",
    "            \n",
    "            llim = lower_lim[metric]\n",
    "            ulim = upper_lim[metric]\n",
    "            \n",
    "            if llim <= value <= ulim:\n",
    "                is_global_outlier = False\n",
    "                break\n",
    "        \n",
    "        if is_global_outlier:\n",
    "            obvious_outliers.append(index)\n",
    "    print(\"-----------------------------\")\n",
    "    print(f\"Total global outliers: {len(obvious_outliers)}\")\n",
    "    return outliers, obvious_outliers\n",
    "    \n",
    "    \n",
    "outliers, obvious_outliers = identify_outliers(df, combined_list_numerical, lower_lim, upper_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a66e0c4",
   "metadata": {},
   "source": [
    "Since we know that aren't outliers in the variables first_order and last_order, let's remove this features and analyse if there are any Total global outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd65d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list_numerical_ = [col for col in combined_list_numerical if col not in ['first_order', 'last_order']]\n",
    "\n",
    "outliers, obvious_outliers = identify_outliers(df, combined_list_numerical_, lower_lim, upper_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "43fb4c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter that will verify if an observation has every characteristic in the Interquartile Range or not \n",
    "filters_iqr = []                                            \n",
    "for metric in combined_list_numerical:\n",
    "    llim = lower_lim[metric]\n",
    "    ulim = upper_lim[metric]\n",
    "    filters_iqr.append(df[metric].between(llim, ulim, inclusive='neither'))\n",
    "\n",
    "filters_iqr_all = pd.concat(filters_iqr, axis=1).all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6707c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_iqr_all  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888f2090",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df[filters_iqr_all] == 'False'])      #These are the features that have at least one of its characteristics considered as an outlier (out of the IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iqr = df[filters_iqr_all]\n",
    "print('Percentage of data kept after removing outliers:', 100*(np.round(df_iqr.shape[0] / df.shape[0], decimals=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e045f16b",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"remove\">\n",
    "\n",
    "## 4.2 Manual Removal\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5fdecfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_man = (\n",
    "     (df['customer_age']<=80)  \n",
    "    &\n",
    "    (df['vendor_count']<=40)\n",
    "    &\n",
    "    (df['product_count']<=80)  \n",
    "    &\n",
    "    (df['is_chain']<=60)\n",
    "    &\n",
    "    (df['HR_0']<=10)\n",
    "    &\n",
    "    (df['HR_1']<=10)\n",
    "    &\n",
    "    (df['HR_2']<=10)  \n",
    "    &\n",
    "    (df['HR_3']<=10) \n",
    "    &\n",
    "    (df['HR_4']<=10) \n",
    "    &\n",
    "    (df['HR_5']<=10) \n",
    "    &\n",
    "    (df['HR_6']<=10) \n",
    "    &\n",
    "    (df['HR_7']<=10) \n",
    "    &\n",
    "    (df['HR_8']<=15) \n",
    "    &\n",
    "    (df['HR_9']<=15) \n",
    "    &\n",
    "    (df['HR_10']<=15) \n",
    "    &\n",
    "    (df['HR_11']<=15) \n",
    "    &\n",
    "    (df['HR_12']<=15) \n",
    "    &\n",
    "    (df['HR_13']<=15) \n",
    "    &\n",
    "    (df['HR_14']<=10) \n",
    "    &\n",
    "    (df['HR_15']<=10) \n",
    "    &\n",
    "    (df['HR_16']<=15) \n",
    "    &\n",
    "    (df['HR_17']<=15) \n",
    "    &\n",
    "    (df['HR_18']<=15) \n",
    "    &\n",
    "    (df['HR_19']<=15) \n",
    "    &\n",
    "    (df['HR_20']<=10) \n",
    "    &\n",
    "    (df['HR_21']<=10) \n",
    "    &\n",
    "    (df['HR_22']<=10) \n",
    "    &\n",
    "    (df['HR_23']<=10) \n",
    "    &\n",
    "    (df['CUI_American']<=150)\n",
    "    &\n",
    "    (df['CUI_Asian']<=200)\n",
    "    &\n",
    "    (df['CUI_Beverages']<=150)  \n",
    "    &\n",
    "    (df['CUI_Cafe']<=150) \n",
    "    &\n",
    "    (df['CUI_Chicken Dishes']<=50) \n",
    "    &\n",
    "    (df['CUI_Chinese']<=100) \n",
    "    &\n",
    "    (df['CUI_Desserts']<=100) \n",
    "    &\n",
    "    (df['CUI_Healthy']<=150) \n",
    "    &\n",
    "    (df['CUI_Indian']<=150) \n",
    "    &\n",
    "    (df['CUI_Italian']<=150) \n",
    "    &\n",
    "    (df['CUI_Japanese']<=150) \n",
    "    &\n",
    "    (df['CUI_Noodle Dishes']<=100) \n",
    "    &\n",
    "    (df['CUI_OTHER']<=200) \n",
    "    &\n",
    "    (df['CUI_Street Food / Snacks']<=200) \n",
    "    &\n",
    "    (df['CUI_Thai']<=150)\n",
    "    & \n",
    "    (df['Sunday']<=15)\n",
    "    &\n",
    "    (df['Monday']<=15)\n",
    "    &\n",
    "    (df['Tuesday']<=15)  \n",
    "    &\n",
    "    (df['Wednesday']<=15) \n",
    "    &\n",
    "    (df['Thursday']<=15) \n",
    "    &\n",
    "    (df['Friday']<=15) \n",
    "    &\n",
    "    (df['Saturday']<=15)  \n",
    ")\n",
    "\n",
    "df_outliers = df[filters_man]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961b32cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of data kept after removing outliers:', 100*(np.round(df_outliers.shape[0] / df.shape[0], decimals=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a760178f",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"combo\">\n",
    "\n",
    "## 4.3 Combining different outlier methods\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df[(filters_iqr_all | filters_man)] \n",
    "\n",
    "\n",
    "print('Percentage of data kept after removing outliers:', np.round(df_out.shape[0] / df.shape[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "94a7ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the manual filtering version\n",
    "\n",
    "df = df_outliers.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0541fb53",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"featengi\">\n",
    "\n",
    "# 5. Feature Engineering\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672cf68d",
   "metadata": {},
   "source": [
    "  - Time Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "29c99b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time Periods\n",
    "df['early_morning(0h-5h)'] = df.filter(regex=r'^HR_[0-5]$').sum(axis=1).astype(int)\n",
    "\n",
    "df['morning(6h-11h)'] = df.filter(regex=r'^HR_([6-9]|1[0-1])$').sum(axis=1).astype(int)\n",
    "\n",
    "df['afternoon(12h-17h)']= df.filter(regex=r'^HR_1[2-7]$').sum(axis=1).astype(int)\n",
    "\n",
    "df['night(18h-23h)'] = df.filter(regex=r'^HR_(1[8-9]|2[0-3])$').sum(axis=1).astype(int)\n",
    "\n",
    "time_columns = ['early_morning(0h-5h)','morning(6h-11h)','afternoon(12h-17h)', 'night(18h-23h)']\n",
    "time_counts = df[time_columns].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97231a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "time_counts.plot(kind='bar', \n",
    "                 color='steelblue', \n",
    "                 edgecolor='black')\n",
    "\n",
    "plt.title('Number of Orders for Time Period')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Number of Ordes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cba83b",
   "metadata": {},
   "source": [
    "  - Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e68db8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age Group\n",
    "age_labels = ['Teenagers (15-19)', 'Young Adults (20-29)', 'Adults (30-49)', 'Middle-aged (50-64)', 'Seniors (65+)']\n",
    "df['age_group'] = pd.cut(df['customer_age'], \n",
    "                         bins=[15, 20, 30, 50, 65, np.inf], \n",
    "                         labels=age_labels, \n",
    "                         right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='age_group', data=df, color='steelblue',edgecolor='black')\n",
    "\n",
    "plt.title('Count of Age Groups', fontsize=16)\n",
    "plt.xlabel('Age Group', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf018ad8",
   "metadata": {},
   "source": [
    "- Sum of Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3b0ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a new Feature that contains the sum of orders by customer (it has the same info as DOW_counts and HR_counts)\n",
    "df['Sum_of_Orders'] = df[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea184ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "col='Sum_of_Orders'\n",
    "# Calculate key statistics\n",
    "mean = df[col].mean()\n",
    "median = df[col].median()\n",
    "std_dev = df[col].std()\n",
    "min_val = df[col].min()\n",
    "max_val = df[col].max()\n",
    "skewness = df[col].skew()\n",
    "kurtosis = df[col].kurt()\n",
    "\n",
    "# Display the statistics\n",
    "print(f'  Mean: {mean:.2f}')\n",
    "print(f'  Median: {median:.2f}')\n",
    "print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "print(f'  Min: {min_val}')\n",
    "print(f'  Max: {max_val}')\n",
    "print(f'  Skewness: {skewness:.2f}')\n",
    "print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "print('-' * 50 )\n",
    "    \n",
    "# Visualization of each Variable\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[col], bins=10,color='steelblue' )\n",
    "plt.title(f'Histogram of {col}')\n",
    "\n",
    "# Boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df[col], color='steelblue')\n",
    "plt.title(f'Boxplot of {col}')\n",
    "\n",
    "# Analyze outliers for the specified numerical variables\n",
    "outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "print(f'Count of outliers: {outlier_count}')\n",
    "print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "print(f'Lower Lim:{lower_lim}')\n",
    "print(f'Upper Lim:{upper_lim}')\n",
    "print('-' * 40)\n",
    "   \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33c20b9",
   "metadata": {},
   "source": [
    "- Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b9a416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the maximum number of days (most recent day in dataset)\n",
    "max_days = df['last_order'].max()\n",
    "\n",
    "# Calculate recency\n",
    "df['recency'] = max_days - df['last_order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c139196",
   "metadata": {},
   "outputs": [],
   "source": [
    "col='recency'\n",
    "# Calculate key statistics\n",
    "mean = df[col].mean()\n",
    "median = df[col].median()\n",
    "std_dev = df[col].std()\n",
    "min_val = df[col].min()\n",
    "max_val = df[col].max()\n",
    "skewness = df[col].skew()\n",
    "kurtosis = df[col].kurt()\n",
    "\n",
    "# Display the statistics\n",
    "print(f'  Mean: {mean:.2f}')\n",
    "print(f'  Median: {median:.2f}')\n",
    "print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "print(f'  Min: {min_val}')\n",
    "print(f'  Max: {max_val}')\n",
    "print(f'  Skewness: {skewness:.2f}')\n",
    "print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "print('-' * 50 )\n",
    "    \n",
    "# Visualization of each Variable\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[col], bins=10, color='steelblue')\n",
    "plt.title(f'Histogram of {col}')\n",
    "\n",
    "# Boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df[col], color='steelblue')\n",
    "plt.title(f'Boxplot of {col}')\n",
    "\n",
    "# Analyze outliers for the specified numerical variables\n",
    "outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "print(f'Count of outliers: {outlier_count}')\n",
    "print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "print(f'Lower Lim:{lower_lim}')\n",
    "print(f'Upper Lim:{upper_lim}')\n",
    "print('-' * 40)\n",
    "   \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1439ea1f",
   "metadata": {},
   "source": [
    "- Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2a4e1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate active period\n",
    "df['active_period'] = df['last_order'] - df['first_order'] + 1\n",
    "\n",
    "# Calculate frequency\n",
    "df['frequency'] = df['Sum_of_Orders'] / df['active_period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa50100",
   "metadata": {},
   "outputs": [],
   "source": [
    "col='frequency'\n",
    "# Calculate key statistics\n",
    "mean = df[col].mean()\n",
    "median = df[col].median()\n",
    "std_dev = df[col].std()\n",
    "min_val = df[col].min()\n",
    "max_val = df[col].max()\n",
    "skewness = df[col].skew()\n",
    "kurtosis = df[col].kurt()\n",
    "\n",
    "# Display the statistics\n",
    "print(f'  Mean: {mean:.2f}')\n",
    "print(f'  Median: {median:.2f}')\n",
    "print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "print(f'  Min: {min_val}')\n",
    "print(f'  Max: {max_val}')\n",
    "print(f'  Skewness: {skewness:.2f}')\n",
    "print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "print('-' * 50 )\n",
    "    \n",
    "# Visualization of each Variable\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[col], bins=10, color='steelblue')\n",
    "plt.title(f'Histogram of {col}')\n",
    "\n",
    "# Boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df[col], color='steelblue')\n",
    "plt.title(f'Boxplot of {col}')\n",
    "\n",
    "# Analyze outliers for the specified numerical variables\n",
    "outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "print(f'Count of outliers: {outlier_count}')\n",
    "print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "print(f'Lower Lim:{lower_lim}')\n",
    "print(f'Upper Lim:{upper_lim}')\n",
    "print('-' * 40)\n",
    "   \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b0f75",
   "metadata": {},
   "source": [
    "- Monetary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2bd9b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total spend per customer\n",
    "df['total_spend'] = df[CUI_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aed16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "col='total_spend'\n",
    "# Calculate key statistics\n",
    "mean = df[col].mean()\n",
    "median = df[col].median()\n",
    "std_dev = df[col].std()\n",
    "min_val = df[col].min()\n",
    "max_val = df[col].max()\n",
    "skewness = df[col].skew()\n",
    "kurtosis = df[col].kurt()\n",
    "\n",
    "# Display the statistics\n",
    "print(f'  Mean: {mean:.2f}')\n",
    "print(f'  Median: {median:.2f}')\n",
    "print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "print(f'  Min: {min_val}')\n",
    "print(f'  Max: {max_val}')\n",
    "print(f'  Skewness: {skewness:.2f}')\n",
    "print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "print('-' * 50 )\n",
    "    \n",
    "# Visualization of each Variable\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[col], bins=10, color='steelblue')\n",
    "plt.title(f'Histogram of {col}')\n",
    "\n",
    "# Boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df[col], color='steelblue')\n",
    "plt.title(f'Boxplot of {col}')\n",
    "\n",
    "# Analyze outliers for the specified numerical variables\n",
    "outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "print(f'Count of outliers: {outlier_count}')\n",
    "print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "print(f'Lower Lim:{lower_lim}')\n",
    "print(f'Upper Lim:{upper_lim}')\n",
    "print('-' * 40)\n",
    "   \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eabb248",
   "metadata": {},
   "source": [
    "RFM \n",
    "- Recency = 'recency'\n",
    "- Frequency = 'frequency'\n",
    "- moentary = 'total_spend'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7932d6a2",
   "metadata": {},
   "source": [
    "- Cuisine Diversity \n",
    "\n",
    "We decided to create a new variable called cuisine_diversity to measure the variety of cuisines each customer orders from. This variable will help us analyze which age groups or regions/cities tend to explore a wider range of cuisines, indicating openness to new experiences. Conversely, it will allow us to identify customers who stick to fewer options, showing a strong preference for specific types of cuisine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6909eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuisine diversity (number of different cuisines ordered)\n",
    "df['cuisine_diversity'] = (df[CUI_columns] > 0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col='cuisine_diversity'\n",
    "# Calculate key statistics\n",
    "mean = df[col].mean()\n",
    "median = df[col].median()\n",
    "std_dev = df[col].std()\n",
    "min_val = df[col].min()\n",
    "max_val = df[col].max()\n",
    "skewness = df[col].skew()\n",
    "kurtosis = df[col].kurt()\n",
    "\n",
    "# Display the statistics\n",
    "print(f'  Mean: {mean:.2f}')\n",
    "print(f'  Median: {median:.2f}')\n",
    "print(f'  Standard Deviation: {std_dev:.2f}')\n",
    "print(f'  Min: {min_val}')\n",
    "print(f'  Max: {max_val}')\n",
    "print(f'  Skewness: {skewness:.2f}')\n",
    "print(f'  Kurtosis: {kurtosis:.2f}')\n",
    "print('-' * 50 )\n",
    "    \n",
    "# Visualization of each Variable\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df[col], bins=10, color='steelblue')\n",
    "plt.title(f'Histogram of {col}')\n",
    "\n",
    "# Boxplot\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df[col], color='steelblue')\n",
    "plt.title(f'Boxplot of {col}')\n",
    "\n",
    "# Analyze outliers for the specified numerical variables\n",
    "outlier_count, outlier_percentage, lower_lim, upper_lim = analyze_outliers(df[col])\n",
    "  \n",
    "print(f'Count of outliers: {outlier_count}')\n",
    "print(f'Percentage of outliers: {outlier_percentage:.2f}%')\n",
    "print(f'Lower Lim:{lower_lim}')\n",
    "print(f'Upper Lim:{upper_lim}')\n",
    "print('-' * 40)\n",
    "   \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7944d11e",
   "metadata": {},
   "source": [
    "- City\n",
    "  \n",
    "Aggregate Regions by the First Digit, which indicates the City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5fde21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new Feature customer_city dividied into categories \n",
    "def categorize_city(customer_region):\n",
    "    if pd.isna(customer_region):  # Check if the value is NaN\n",
    "        return np.nan \n",
    "    elif customer_region== \"-\":\n",
    "        return \"Other\"\n",
    "    elif customer_region[0].isdigit():\n",
    "        return customer_region[0]\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "\n",
    "# Apply the function to create the new 'customer_city' column\n",
    "df['customer_city'] = df['customer_region'].apply(categorize_city)\n",
    "\n",
    "print(df['customer_city'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ca9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the count plot\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x='customer_city', data=df, palette='tab10')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('City', fontsize=14)\n",
    "plt.xlabel('customer_city', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef2d40",
   "metadata": {},
   "source": [
    "- Weekdays and Weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d496dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Weekdays'] = df[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']].sum(axis=1)\n",
    "df['Weekends'] = df[['Saturday', 'Sunday']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data for easier plotting\n",
    "df_melted = df[['Weekdays', 'Weekends']].melt(var_name='Day Type', value_name='Total')\n",
    "\n",
    "# Create a count plot \n",
    "sns.barplot(data=df_melted, x='Day Type', y='Total', estimator=sum, ci=None, palette=\"tab10\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Comparison of Total Values: Weekdays vs Weekends')\n",
    "plt.xlabel('Day Type')\n",
    "plt.ylabel('Total Value')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c0a18",
   "metadata": {},
   "source": [
    "- Types of cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5410f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CUI_OTHER'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c06553",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['CUI_OTHER'] != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "85eb325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to group cuisines by style/type\n",
    "groupings = {\n",
    "    'Main Courses': [\n",
    "        'CUI_American', 'CUI_Chicken Dishes', 'CUI_Indian', \n",
    "        'CUI_Italian', 'CUI_Thai', 'CUI_Chinese', 'CUI_Asian', 'CUI_Japanese'\n",
    "    ],\n",
    "    'Snacks and Street Food': [\n",
    "        'CUI_Street Food / Snacks', 'CUI_Noodle Dishes', 'CUI_Cafe'\n",
    "    ],\n",
    "    'Desserts and Beverages': [\n",
    "        'CUI_Desserts', 'CUI_Beverages'\n",
    "    ],\n",
    "    'Healthy and Special Diets': [\n",
    "        'CUI_Healthy'\n",
    "    ],\n",
    "    'Other': [\n",
    "        'CUI_OTHER'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Function to aggregate money spent into cuisine groups\n",
    "def aggregate_to_groups(df, groupings):\n",
    "    # Create an empty DataFrame for the grouped values with the same index as df\n",
    "    grouped_df = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # For each group, sum the relevant columns\n",
    "    for group, cuisines in groupings.items():\n",
    "        # Check if all columns in the group exist in the DataFrame\n",
    "        if all(cuisine in df.columns for cuisine in cuisines):\n",
    "            grouped_df[group] = df[cuisines].sum(axis=1)\n",
    "        else:\n",
    "            missing_columns = [cuisine for cuisine in cuisines if cuisine not in df.columns]\n",
    "            print(f\"Missing columns for group '{group}': {missing_columns}\")\n",
    "    \n",
    "    # Return the DataFrame with the new group columns\n",
    "    return grouped_df\n",
    "\n",
    "# Aggregate the money spent into cuisine groups\n",
    "grouped_df = aggregate_to_groups(df, groupings)\n",
    "\n",
    "# Concatenate the grouped_df to the original df\n",
    "df= pd.concat([df, grouped_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9917411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing up the values for each group\n",
    "group_totals = grouped_df.sum().sort_values(ascending=False)\n",
    "\n",
    "# Plotting the aggregated values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=group_totals.index, y=group_totals.values, palette=\"tab10\")\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title(\"Total Spending by Cuisine Group\", fontsize=16)\n",
    "plt.xlabel(\"Cuisine Group\", fontsize=14)\n",
    "plt.ylabel(\"Total Spending\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right')  \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8094b9a",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"visualization\">\n",
    "\n",
    "# 6. Visualizations\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d0bbb",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"corr\">\n",
    "\n",
    "## 6.1 Correlations and Heatmaps\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9529bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df[['customer_age', \n",
    "              'vendor_count',\n",
    "               'product_count', \n",
    "              'first_order', \n",
    "              'last_order'\n",
    "             ]].corr()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f89667",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_corr, \n",
    "            annot=True, \n",
    "            cmap='PiYG')\n",
    "\n",
    "plt.title('Correlation Heatmap between numerical variables', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d91312",
   "metadata": {},
   "source": [
    "- product_count and vendor_count have a very high correlation (0,86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc172164",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_all=df[['customer_age', 'vendor_count',\n",
    "       'product_count', 'first_order', 'last_order', 'CUI_American', 'CUI_Asian', 'CUI_Beverages',\n",
    "       'CUI_Cafe', 'CUI_Chicken Dishes', 'CUI_Chinese', 'CUI_Desserts',\n",
    "       'CUI_Healthy', 'CUI_Indian', 'CUI_Italian', 'CUI_Japanese',\n",
    "       'CUI_Noodle Dishes', 'CUI_OTHER', 'CUI_Street Food / Snacks',\n",
    "       'CUI_Thai', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday',\n",
    "       'Saturday', 'Sunday', 'HR_0', 'HR_1', 'HR_2', 'HR_3', 'HR_4', 'HR_5',\n",
    "       'HR_6', 'HR_7', 'HR_8', 'HR_9', 'HR_10', 'HR_11', 'HR_12', 'HR_13',\n",
    "       'HR_14', 'HR_15', 'HR_16', 'HR_17', 'HR_18', 'HR_19', 'HR_20', 'HR_21',\n",
    "       'HR_22', 'HR_23']].corr()\n",
    "\n",
    "plt.figure(figsize=(20, 20)) \n",
    "\n",
    "\n",
    "sns.heatmap(df_corr_all, annot=True,\n",
    "            linewidths=0.7, vmin=-1, vmax=1, square=True,\n",
    "            cbar_kws={'shrink': 0.75, 'aspect': 30}, \n",
    "            annot_kws={'size': 6 },  \n",
    "            cmap='PiYG')  \n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(rotation=0, fontsize=12)\n",
    "\n",
    "plt.title('Correlation Heatmap with all numeric variables', fontsize=16, weight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the aggregated activity, initializing with zeros\n",
    "heatmap_data = pd.DataFrame(index=dow_columns, columns=hr_columns)\n",
    "\n",
    "# Sum of the hourly activity for each day and fill in the heatmap data\n",
    "for day in dow_columns:\n",
    "    # Summing the hourly columns for the current day and filling NaNs with zero\n",
    "    heatmap_data.loc[day] = df.loc[df[day]  > 0, hr_columns].sum().fillna(0)\n",
    "\n",
    "# Convert all data to numeric (float)\n",
    "heatmap_data = heatmap_data.astype(float)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(30, 15))\n",
    "sns.heatmap(heatmap_data, \n",
    "            cmap='YlGnBu', \n",
    "            linewidths=1, \n",
    "            annot=True, \n",
    "            square=True, \n",
    "            fmt='.0f')\n",
    "plt.title('Heatmap of Hourly Activity Throughout the Week')\n",
    "plt.xlabel('Hour of the Day (0-23)')\n",
    "plt.ylabel('Day of the Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store the aggregated activity, initializing with zeros\n",
    "heatmap_data = pd.DataFrame(index=dow_columns, columns=time_columns)\n",
    "\n",
    "# Sum the hourly activity for each day and fill in the heatmap data\n",
    "for day in dow_columns:\n",
    "    # Summing the hourly columns for the current day and filling NaNs with zero\n",
    "    heatmap_data.loc[day] = df.loc[df[day] > 0, time_columns].sum().fillna(0)\n",
    "\n",
    "# Convert all data to numeric (float)\n",
    "heatmap_data = heatmap_data.astype(float)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(heatmap_data, \n",
    "            cmap='YlGnBu', \n",
    "            linewidths=0.5, \n",
    "            annot=True, \n",
    "            square=True,\n",
    "            annot_kws={'size': 10 }, \n",
    "            fmt='.0f')\n",
    "plt.title('Heatmap of Period of Time Activity Throughout the Week')\n",
    "plt.xlabel('Period of Time')\n",
    "plt.ylabel('Day of the Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7882484",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_by_age = df.groupby('age_group')[CUI_columns].sum()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cuisine_by_age, \n",
    "            annot=True,\n",
    "            annot_kws={'size': 10 }, \n",
    "            cmap='YlGnBu', \n",
    "            fmt='.0f', \n",
    "            square=True)\n",
    "\n",
    "plt.title('Average Spend on each Cuisine by Age', fontsize=16)\n",
    "plt.xlabel('Cuisine Type', fontsize=12)\n",
    "plt.ylabel('Age Group', fontsize=12)\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by region and sum the DOW\n",
    "cuisine_by_region = df.groupby('customer_region')[dow_columns].sum()  \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cuisine_by_region, \n",
    "            annot=True,\n",
    "            annot_kws={'size': 10}, \n",
    "            cmap='YlGnBu', \n",
    "            fmt='.0f', \n",
    "            square=True)\n",
    "\n",
    "plt.title('DOW Activity by Region', fontsize=16)\n",
    "plt.xlabel('DOW', fontsize=12)  \n",
    "plt.ylabel('Region', fontsize=12)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae9654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by city and sum the DOW\n",
    "cuisine_by_region = df.groupby('customer_city')[dow_columns].sum()  \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cuisine_by_region, \n",
    "            annot=True,\n",
    "            annot_kws={'size': 10}, \n",
    "            cmap='YlGnBu', \n",
    "            fmt='.0f', \n",
    "            square=True)\n",
    "\n",
    "plt.title('DOW Activity by city', fontsize=16)\n",
    "plt.xlabel('DOW', fontsize=12)  \n",
    "plt.ylabel('city', fontsize=12)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b9b0c",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"multi\">\n",
    "\n",
    "## 6.2 Multivariate Analysis\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6447e810",
   "metadata": {},
   "source": [
    "- Payment Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06262d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_counts = df.groupby(['age_group', 'payment_method']).size().unstack(fill_value=0)\n",
    "\n",
    "colors=['#87CEEB','#00BFFF','#4682B4']\n",
    "payment_counts.plot(kind='bar', \n",
    "                    stacked=False, \n",
    "                    figsize=(10, 6), \n",
    "                    color=colors, \n",
    "                    edgecolor='black') \n",
    "\n",
    "plt.title('Payment Methods by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Number of orders')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.legend(title='Payment Method')\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613893b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_counts_region = df.groupby(['customer_region', 'payment_method']).size().unstack(fill_value=0)\n",
    "\n",
    "colors=['#87CEEB','#00BFFF','#4682B4']\n",
    "payment_counts_region.plot(kind='bar', \n",
    "                    stacked=False, \n",
    "                    figsize=(10, 6), \n",
    "                    color=plt.cm.tab10.colors, \n",
    "                    edgecolor='black') \n",
    "\n",
    "plt.title('Payment Methods by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Number of orders')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.legend(title='Payment Method')\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f280f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_counts_region = df.groupby(['customer_city', 'payment_method']).size().unstack(fill_value=0)\n",
    "\n",
    "colors=['#87CEEB','#00BFFF','#4682B4']\n",
    "payment_counts_region.plot(kind='bar', \n",
    "                    stacked=False, \n",
    "                    figsize=(10, 6), \n",
    "                    color=plt.cm.tab10.colors, \n",
    "                    edgecolor='black') \n",
    "\n",
    "plt.title('Payment Methods by City')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Number of orders')\n",
    "plt.xticks(rotation=0)  \n",
    "plt.legend(title='Payment Method')\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef59360",
   "metadata": {},
   "source": [
    "- Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by region and age group\n",
    "age_counts = df.groupby(['customer_region', 'age_group']).size().reset_index(name='count')\n",
    "\n",
    "# Creating a pivot table\n",
    "pivot_age_counts = age_counts.pivot(index='customer_region', columns='age_group', values='count').fillna(0)\n",
    "\n",
    "# Plotting the stacked bar chart\n",
    "pivot_age_counts.plot(kind='bar', \n",
    "                      stacked=True, \n",
    "                      figsize=(10, 6), \n",
    "                      color=plt.cm.tab10.colors) # Ensuring the color palette is correct\n",
    "\n",
    "plt.title('Distribution of Age Groups by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.legend(title='Age Group', bbox_to_anchor=(1.05, 1), loc='upper left')  \n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by city and age group\n",
    "age_counts_city = df.groupby(['customer_city', 'age_group']).size().reset_index(name='count')\n",
    "\n",
    "# Create the stacked bar plot\n",
    "age_counts_city_pivot = age_counts_city.pivot(index='customer_city', columns='age_group', values='count').fillna(0)\n",
    "\n",
    "age_counts_city_pivot.plot(kind='bar', \n",
    "                            stacked=True, \n",
    "                            figsize=(10, 6),\n",
    "                            color=plt.cm.tab10.colors) # Ensuring the color palette is correct\n",
    "plt.title('Distribution of Age Groups by City')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.legend(title='Age Group', bbox_to_anchor=(1.05, 1), loc='upper left')  \n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29771788",
   "metadata": {},
   "source": [
    "- Cuisine Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_counts = df.groupby('customer_region')[CUI_columns].sum().reset_index()\n",
    "\n",
    "cuisine_counts_ = cuisine_counts.melt(id_vars='customer_region', \n",
    "                                            value_vars=CUI_columns, \n",
    "                                            var_name='cuisine_type', \n",
    "                                            value_name='total_expenditure')\n",
    "\n",
    "top_cuisines = (\n",
    "    cuisine_counts_.groupby('customer_region')\n",
    "    .apply(lambda x: x.nlargest(3, 'total_expenditure'))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "top_cuisine_counts = top_cuisines.pivot(index='customer_region', \n",
    "                                        columns='cuisine_type', \n",
    "                                        values='total_expenditure').fillna(0)\n",
    "\n",
    "\n",
    "num_cuisines = top_cuisine_counts.shape[1]\n",
    "colors = plt.cm.Paired(np.linspace(0, 1, num_cuisines)) \n",
    "\n",
    "\n",
    "top_cuisine_counts.plot(kind='bar', \n",
    "                        stacked=True, \n",
    "                        figsize=(10, 6), \n",
    "                        color=colors)\n",
    "\n",
    "plt.title('Top 3 Cuisine Type by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Total Expenditure')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Type of Cuisine', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd445db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_counts = df.groupby('customer_city')[CUI_columns].sum().reset_index()\n",
    "\n",
    "cuisine_counts_1= cuisine_counts.melt(id_vars='customer_city', \n",
    "                                            value_vars=CUI_columns, \n",
    "                                            var_name='cuisine_type', \n",
    "                                            value_name='total_expenditure')\n",
    "\n",
    "top_cuisines = (\n",
    "    cuisine_counts_1.groupby('customer_city')\n",
    "    .apply(lambda x: x.nlargest(3, 'total_expenditure'))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "top_cuisine_counts = top_cuisines.pivot(index='customer_city', \n",
    "                                        columns='cuisine_type', \n",
    "                                        values='total_expenditure').fillna(0)\n",
    "\n",
    "\n",
    "num_cuisines = top_cuisine_counts.shape[1]\n",
    "colors = plt.cm.Paired(np.linspace(0, 1, num_cuisines)) \n",
    "\n",
    "\n",
    "top_cuisine_counts.plot(kind='bar', \n",
    "                        stacked=True, \n",
    "                        figsize=(10, 6), \n",
    "                        color=colors)\n",
    "\n",
    "plt.title('Top 3 Cuisine Type by City')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Total Expenditure')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Type of Cuisine', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a57b86",
   "metadata": {},
   "source": [
    "- Total Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf92d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by region and sum the total spending\n",
    "region_spend = df.groupby('customer_region')['total_spend'].sum().reset_index()\n",
    "\n",
    "region_spend = region_spend.sort_values(by='total_spend', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='customer_region', y='total_spend', data=region_spend, palette=\"tab10\")\n",
    "\n",
    "plt.title(\"Total Spending per Region\")\n",
    "plt.xlabel(\"Customer Region\")\n",
    "plt.ylabel(\"Total Spend\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc80cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by age group and  total spending\n",
    "region_spend = df.groupby('customer_city')['total_spend'].sum().reset_index()\n",
    "\n",
    "region_spend = region_spend.sort_values(by='total_spend', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='customer_city', y='total_spend', data=region_spend, palette=\"tab10\")\n",
    "\n",
    "plt.title(\"Total Spending per City\")\n",
    "plt.xlabel(\"City\")\n",
    "plt.ylabel(\"Total Spend\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by age group and  total spending\n",
    "region_spend = df.groupby('age_group')['total_spend'].sum().reset_index()\n",
    "\n",
    "region_spend = region_spend.sort_values(by='total_spend', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='age_group', y='total_spend', data=region_spend, palette=\"tab10\")\n",
    "\n",
    "plt.title(\"Total Spending per Age Group\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Total Spend\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753eb367",
   "metadata": {},
   "source": [
    "- Cuisine Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f88a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by region and cuisine diversity\n",
    "region_spend = df.groupby('customer_region')['cuisine_diversity'].sum().reset_index()\n",
    "\n",
    "region_spend = region_spend.sort_values(by='cuisine_diversity', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='customer_region', y='cuisine_diversity', data=region_spend, palette=\"tab10\")\n",
    "\n",
    "plt.title(\"Cuisine Diversity per Region\")\n",
    "plt.xlabel(\"Customer Region\")\n",
    "plt.ylabel(\"Cuisine Diveristy\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ecf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by region and cuisine diversity\n",
    "region_spend = df.groupby('customer_city')['cuisine_diversity'].sum().reset_index()\n",
    "\n",
    "region_spend = region_spend.sort_values(by='cuisine_diversity', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='customer_city', y='cuisine_diversity', data=region_spend, palette=\"tab10\")\n",
    "\n",
    "plt.title(\"Cuisine Diversity per city\")\n",
    "plt.xlabel(\"Customer city\")\n",
    "plt.ylabel(\"Cuisine Diveristy\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def1814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by age group and cuisine diversity\n",
    "region_spend = df.groupby('age_group')['cuisine_diversity'].sum().reset_index()\n",
    "\n",
    "region_spend = region_spend.sort_values(by='cuisine_diversity', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='age_group', y='cuisine_diversity', data=region_spend, palette=\"tab10\")\n",
    "\n",
    "plt.title(\"Cuisine Diversity per Age Group\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Cuisine Diversity\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564d1c4",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"enc\">\n",
    "\n",
    "# 7. Encoding\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0fea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "813cdef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['customer_region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d2c2819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohc = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2ce2a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_new = ['last_promo', 'payment_method', 'age_group', 'is_chain', 'customer_city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "831eb05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'age_group' and 'last_promo' from the list of categorical features\n",
    "columns_to_remove = ['age_group', 'last_promo']  \n",
    "cf_for_ohc = [col for col in categorical_features_new if col not in columns_to_remove]\n",
    "\n",
    "# Initialize the encoder with the chosen settings\n",
    "ohc = OneHotEncoder(sparse_output=False, drop=None)\n",
    "\n",
    "# Fit the encoder on the selected categorical features\n",
    "ohc.fit(df_ohc[cf_for_ohc])\n",
    "\n",
    "# Transform the selected categorical features\n",
    "ohc_features = ohc.transform(df_ohc[cf_for_ohc])\n",
    "\n",
    "# Create a DataFrame with encoded feature names, adding 'enc_' prefix to the columns\n",
    "ohc_df = pd.DataFrame(\n",
    "    ohc_features,\n",
    "    index=df_ohc.index,\n",
    "    columns=[f\"enc_{name}\" for name in ohc.get_feature_names_out(cf_for_ohc)]\n",
    ")\n",
    "\n",
    "# Concatenate the encoded features back to the original dataset (without dropping the original columns)\n",
    "ohc_encoded = pd.concat(\n",
    "    [df_ohc, ohc_df],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb20c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ohc_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0c6c8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder for 'age_group' with categories\n",
    "ordinal_encoder = OrdinalEncoder(\n",
    "    categories=[['Teenagers (15-19)', 'Young Adults (20-29)', 'Adults (30-49)', 'Middle-aged (50-64)', 'Seniors (65-80)']],\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-1  # Use -1 for unknown categories\n",
    ")\n",
    "\n",
    "if 'age_group' not in df_ohc.columns:\n",
    "    raise KeyError(\"The column 'age_group' is not in the DataFrame.\")\n",
    "\n",
    "# Fit and transform the 'age_group' column and add it to the DataFrame with prefix 'enc_'\n",
    "df_ohc['enc_age_group'] = ordinal_encoder.fit_transform(df_ohc[['age_group']])\n",
    "\n",
    "# Map the 'last_promo' feature to binary values\n",
    "promo_mapping = {\n",
    "    'No PROMO': 0,  # No promo maps to 0\n",
    "    'DISCOUNT': 1,   # All promos map to 1\n",
    "    'DELIVERY': 1,\n",
    "    'FREEBIE': 1\n",
    "}\n",
    "\n",
    "# Apply the mapping to create the binary encoded column for 'last_promo' with prefix 'enc_'\n",
    "df_ohc['enc_last_promo'] = df_ohc['last_promo'].map(promo_mapping)\n",
    "\n",
    "# If there are any NaN values in 'enc_last_promo', fill them with 0\n",
    "df_ohc['enc_last_promo'] = df_ohc['enc_last_promo'].fillna(0)\n",
    "\n",
    "# Concatenate the encoded columns with the existing DataFrame\n",
    "df_encoded = pd.concat([ohc_encoded, df_ohc[['enc_age_group', 'enc_last_promo']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9deb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9109205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10535d73",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"scale\">\n",
    "\n",
    "# 8. Scaling\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74ec5d",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"mm\">\n",
    "\n",
    "## 8.1 MinMax Scaling\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e6505894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minmax = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f37e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c5c26db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols =['customer_age', 'vendor_count', 'product_count','first_order', 'last_order',\n",
    "        'CUI_American', 'CUI_Asian', 'CUI_Beverages', 'CUI_Cafe',\n",
    "        'CUI_Chicken Dishes', 'CUI_Chinese', 'CUI_Desserts', 'CUI_Healthy',\n",
    "        'CUI_Indian', 'CUI_Italian', 'CUI_Japanese', 'CUI_Noodle Dishes',\n",
    "        'CUI_OTHER', 'CUI_Street Food / Snacks', 'CUI_Thai', 'Sunday',\n",
    "        'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday',\n",
    "        'HR_0', 'HR_1', 'HR_2', 'HR_3', 'HR_4', 'HR_5', 'HR_6', 'HR_7',\n",
    "        'HR_8', 'HR_9', 'HR_10', 'HR_11', 'HR_12', 'HR_13', 'HR_14',\n",
    "        'HR_15', 'HR_16', 'HR_17', 'HR_18', 'HR_19', 'HR_20', 'HR_21',\n",
    "        'HR_22', 'HR_23', 'early_morning(0h-5h)', 'morning(6h-11h)',\n",
    "        'afternoon(12h-17h)', 'night(18h-23h)','Sum_of_Orders', 'recency', 'active_period', 'frequency',\n",
    "        'total_spend', 'cuisine_diversity','Weekends', 'Main Courses', 'Snacks and Street Food',\n",
    "       'Desserts and Beverages', 'Healthy and Special Diets', 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2738799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MinMaxScaler to scale the data\n",
    "mm_scaler = MinMaxScaler()\n",
    "mm_scaled_feat = mm_scaler.fit_transform(df_minmax[numeric_cols])\n",
    "mm_scaled_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ce43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the fit method is doing:\n",
    "print(\"Parameters fitted:\\n\")\n",
    "pd.DataFrame([mm_scaler.data_min_, mm_scaler.data_max_], columns=numeric_cols, index=['min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "092d3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace original numeric_cols values with mm_scaled_feat values\n",
    "df_minmax[numeric_cols] = mm_scaled_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f7747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking max and min of minmaxed variables\n",
    "df_minmax[numeric_cols].describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5b4382",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"std\">\n",
    "\n",
    "## 8.2 Standard Scaling\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7590099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ee7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_scaler = StandardScaler()\n",
    "ss_scaled_feat = ss_scaler.fit_transform(df_standard[numeric_cols])\n",
    "ss_scaled_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b2d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the fit method is doing:\n",
    "print(\"Parameters fitted:\\n\")\n",
    "pd.DataFrame([ss_scaler.mean_, np.sqrt(ss_scaler.var_)], columns=numeric_cols, index=['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53037c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard[numeric_cols] = ss_scaled_feat\n",
    "df_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c46c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking mean and variance of standardized variables\n",
    "df_standard[numeric_cols].describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e530d9",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"vs\">\n",
    "\n",
    "## 8.3 MinMaxScaler vs StandardScaler vs Original data\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ce272",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"box\">\n",
    "\n",
    "### 8.3.1 Boxplots\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e26208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Grid\n",
    "fig, axes = plt.subplots(\n",
    "    len(numeric_cols), 3, \n",
    "    figsize=(10, len(numeric_cols) * 3), \n",
    "    tight_layout=True, \n",
    "    sharex='col', \n",
    "    sharey='row'\n",
    ")\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    # Original\n",
    "    sns.boxplot(df, x=col, ax=axes[i, 0], width=.4, color='steelblue')\n",
    "    axes[i, 0].set_title('Original')\n",
    "    axes[i, 0].set_ylabel(col)\n",
    "\n",
    "    # MinMaxScaler\n",
    "    sns.boxplot(df_minmax, x=col, ax=axes[i, 1], width=.4, color='steelblue')\n",
    "    axes[i, 1].set_title('MinMaxScaler()')\n",
    "\n",
    "    # StandardScaler\n",
    "    sns.boxplot(df_standard, x=col, ax=axes[i, 2], width=.4, color='steelblue')\n",
    "    axes[i, 2].set_title('StandardScaler()')\n",
    "\n",
    "\n",
    "    axes[i, 0].set_xlabel(None)\n",
    "    axes[i, 1].set_xlabel(None)\n",
    "    axes[i, 2].set_xlabel(None)\n",
    "\n",
    "fig.suptitle('Boxplots', y=1.02)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4002ca",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"histograms\">\n",
    "\n",
    "### 8.3.2 Histograms\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e383541",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Grid for plots\n",
    "fig, axes = plt.subplots(\n",
    "    len(numeric_cols), 3, \n",
    "    figsize=(10, len(numeric_cols) * 3), \n",
    "    tight_layout=True, \n",
    "    sharex='col', \n",
    "    sharey='row'\n",
    ")\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    # Original\n",
    "    sns.histplot(df, x=col, ax=axes[i, 0], binwidth=1, kde=False, color='steelblue')\n",
    "    axes[i, 0].set_title('Original')\n",
    "    axes[i, 0].set_ylabel(col)\n",
    "\n",
    "    # MinMaxScaler\n",
    "    sns.histplot(df_minmax, x=col, ax=axes[i, 1], binwidth=0.1, kde=False)\n",
    "    axes[i, 1].set_title('MinMaxScaler()')\n",
    "\n",
    "    # StandardScaler\n",
    "    sns.histplot(df_standard, x=col, ax=axes[i, 2], binwidth=0.1, kde=False)\n",
    "    axes[i, 2].set_title('StandardScaler()')\n",
    "\n",
    "    axes[i, 0].set_xlabel(None)\n",
    "    axes[i, 1].set_xlabel(None)\n",
    "    axes[i, 2].set_xlabel(None)\n",
    "\n",
    "fig.suptitle('Histograms', y=1.02)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff21978b",
   "metadata": {},
   "source": [
    "Use StandardScaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "08935570",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_standard.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cfe6b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataset before clustering\n",
    "df.to_csv('data_beforeclustering.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
